# VADå»¶è¿Ÿè¡¥å¿ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›VADå»¶è¿Ÿè¡¥å¿åŠŸèƒ½çš„è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚

## åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

### 1. ç®€å•å¯ç”¨å»¶è¿Ÿè¡¥å¿

```python
from cascade.types import VADConfig, AudioConfig
from cascade.processor import create_vad_processor

# åˆ›å»ºåŒ…å«å»¶è¿Ÿè¡¥å¿çš„VADé…ç½®
vad_config = VADConfig(
    backend="silero",
    threshold=0.5,
    chunk_duration_ms=500,
    overlap_ms=16,
    compensation_ms=200  # å¯ç”¨200mså»¶è¿Ÿè¡¥å¿
)

audio_config = AudioConfig(
    sample_rate=16000,
    channels=1,
    dtype="float32"
)

# åˆ›å»ºVADå¤„ç†å™¨
processor = await create_vad_processor(audio_config, vad_config)
```

### 2. å¤„ç†éŸ³é¢‘æµ

```python
import asyncio
import numpy as np

async def process_audio_with_compensation():
    """æ¼”ç¤ºå¸¦å»¶è¿Ÿè¡¥å¿çš„éŸ³é¢‘å¤„ç†"""
    
    # æ¨¡æ‹ŸéŸ³é¢‘æµ
    async def audio_stream():
        for i in range(10):
            # ç”Ÿæˆ500msçš„éŸ³é¢‘æ•°æ®
            chunk_size = 8000  # 16kHz * 0.5s
            audio_data = np.random.randn(chunk_size).astype(np.float32) * 0.1
            yield audio_data
            await asyncio.sleep(0.01)
    
    async with processor:
        # å¤„ç†éŸ³é¢‘æµå¹¶è·å–ç»“æœ
        async for vad_result in processor.process_stream(audio_stream()):
            if vad_result.is_speech:
                if vad_result.is_compensated:
                    print(f"ğŸ¯ è¯­éŸ³å¼€å§‹ï¼ˆå·²è¡¥å¿ï¼‰: "
                          f"åŸå§‹={vad_result.original_start_ms:.1f}ms, "
                          f"è¡¥å¿å={vad_result.start_ms:.1f}ms")
                else:
                    print(f"ğŸ—£ï¸  è¯­éŸ³ç»§ç»­: {vad_result.start_ms:.1f}ms")
            else:
                print(f"ğŸ”‡ é™éŸ³: {vad_result.start_ms:.1f}ms")

# è¿è¡Œç¤ºä¾‹
await process_audio_with_compensation()
```

## é…ç½®é€‰é¡¹è¯¦è§£

### 1. ç¦ç”¨å»¶è¿Ÿè¡¥å¿

```python
# æ–¹æ³•1ï¼šè®¾ç½®ä¸º0
vad_config = VADConfig(
    backend="silero",
    compensation_ms=0  # ç¦ç”¨è¡¥å¿
)

# æ–¹æ³•2ï¼šä¸è®¾ç½®ï¼ˆé»˜è®¤ä¸º0ï¼‰
vad_config = VADConfig(
    backend="silero"
    # compensation_ms é»˜è®¤ä¸º0
)
```

### 2. ä¸åŒè¡¥å¿æ—¶é•¿çš„é€‰æ‹©

```python
# è½»åº¦è¡¥å¿ï¼ˆé€‚åˆé«˜ç²¾åº¦åœºæ™¯ï¼‰
light_compensation = VADConfig(
    backend="silero",
    compensation_ms=100
)

# æ ‡å‡†è¡¥å¿ï¼ˆæ¨èè®¾ç½®ï¼‰
standard_compensation = VADConfig(
    backend="silero",
    compensation_ms=200
)

# å¼ºè¡¥å¿ï¼ˆé€‚åˆå®æ—¶å“åº”è¦æ±‚é«˜çš„åœºæ™¯ï¼‰
strong_compensation = VADConfig(
    backend="silero",
    compensation_ms=300
)
```

## å®é™…åº”ç”¨åœºæ™¯

### 1. å®æ—¶è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ

```python
class RealTimeASR:
    """å®æ—¶è¯­éŸ³è¯†åˆ«ç³»ç»Ÿç¤ºä¾‹"""
    
    def __init__(self):
        self.vad_config = VADConfig(
            backend="silero",
            threshold=0.6,
            compensation_ms=250  # è¾ƒå¼ºè¡¥å¿ç¡®ä¿æ•è·è¯­éŸ³å¼€å¤´
        )
        self.audio_config = AudioConfig(sample_rate=16000, channels=1)
        
    async def start_recognition(self, audio_stream):
        processor = await create_vad_processor(
            self.audio_config, 
            self.vad_config
        )
        
        async with processor:
            speech_buffer = []
            
            async for vad_result in processor.process_stream(audio_stream):
                if vad_result.is_speech:
                    if vad_result.is_compensated:
                        # è¯­éŸ³å¼€å§‹ï¼Œå¼€å§‹æ”¶é›†éŸ³é¢‘
                        print(f"ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆè¡¥å¿äº†{vad_result.original_start_ms - vad_result.start_ms:.0f}msï¼‰")
                        speech_buffer = []
                    
                    # æ”¶é›†è¯­éŸ³æ•°æ®
                    speech_buffer.append(vad_result)
                    
                else:
                    if speech_buffer:
                        # è¯­éŸ³ç»“æŸï¼Œè¿›è¡Œè¯†åˆ«
                        await self.recognize_speech(speech_buffer)
                        speech_buffer = []
                        
    async def recognize_speech(self, speech_data):
        """æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«è¿‡ç¨‹"""
        duration = speech_data[-1].end_ms - speech_data[0].start_ms
        print(f"ğŸ”„ è¯†åˆ«è¯­éŸ³æ®µï¼š{duration:.0f}ms")
```

### 2. è¯­éŸ³æ¿€æ´»æ£€æµ‹

```python
class VoiceActivation:
    """è¯­éŸ³æ¿€æ´»æ£€æµ‹ç¤ºä¾‹"""
    
    def __init__(self, wake_word_threshold=500):
        self.wake_word_threshold = wake_word_threshold  # æœ€çŸ­æ¿€æ´»æ—¶é•¿
        self.vad_config = VADConfig(
            backend="silero",
            threshold=0.7,  # è¾ƒé«˜é˜ˆå€¼é¿å…è¯¯æ¿€æ´»
            compensation_ms=150
        )
        
    async def detect_activation(self, audio_stream):
        processor = await create_vad_processor(
            AudioConfig(sample_rate=16000, channels=1),
            self.vad_config
        )
        
        async with processor:
            speech_start_time = None
            
            async for vad_result in processor.process_stream(audio_stream):
                if vad_result.is_speech:
                    if vad_result.is_compensated:
                        # è®°å½•è¯­éŸ³å¼€å§‹æ—¶é—´ï¼ˆä½¿ç”¨è¡¥å¿åçš„æ—¶é—´ï¼‰
                        speech_start_time = vad_result.start_ms
                        print(f"ğŸ‘‚ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹: {speech_start_time:.1f}ms")
                        
                else:
                    if speech_start_time is not None:
                        # æ£€æŸ¥è¯­éŸ³æŒç»­æ—¶é•¿
                        duration = vad_result.start_ms - speech_start_time
                        if duration >= self.wake_word_threshold:
                            print(f"âœ… è¯­éŸ³æ¿€æ´»ï¼æŒç»­æ—¶é•¿: {duration:.0f}ms")
                            await self.handle_activation()
                        else:
                            print(f"âŒ è¯­éŸ³å¤ªçŸ­ï¼Œå¿½ç•¥: {duration:.0f}ms")
                        
                        speech_start_time = None
                        
    async def handle_activation(self):
        """å¤„ç†è¯­éŸ³æ¿€æ´»äº‹ä»¶"""
        print("ğŸš€ ç³»ç»Ÿæ¿€æ´»ï¼Œå¼€å§‹ç›‘å¬å‘½ä»¤...")
```

## é«˜çº§ç”¨æ³•

### 1. åŠ¨æ€è°ƒæ•´è¡¥å¿å‚æ•°

```python
from cascade.processor.delay_compensator import SimpleDelayCompensator

# åˆ›å»ºç‹¬ç«‹çš„è¡¥å¿å™¨
compensator = SimpleDelayCompensator(compensation_ms=200)

# åŠ¨æ€è°ƒæ•´è¡¥å¿æ—¶é•¿
compensator.set_compensation_ms(150)

# æ£€æŸ¥å½“å‰è®¾ç½®
print(f"å½“å‰è¡¥å¿æ—¶é•¿: {compensator.get_compensation_ms()}ms")
print(f"æ˜¯å¦å¯ç”¨: {compensator.is_enabled()}")

# å¤„ç†VADç»“æœ
vad_result = get_vad_result()  # è·å–VADç»“æœ
compensated_result = compensator.process_result(vad_result)
```

### 2. å¤šéŸ³é¢‘æµå¤„ç†

```python
async def process_multiple_streams():
    """å¤„ç†å¤šä¸ªéŸ³é¢‘æµçš„ç¤ºä¾‹"""
    
    # ä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒçš„è¡¥å¿é…ç½®
    configs = {
        "meeting": VADConfig(backend="silero", compensation_ms=100),
        "phone": VADConfig(backend="silero", compensation_ms=250),
        "broadcast": VADConfig(backend="silero", compensation_ms=150),
    }
    
    processors = {}
    for name, config in configs.items():
        processors[name] = await create_vad_processor(
            AudioConfig(sample_rate=16000, channels=1),
            config
        )
    
    try:
        # å¹¶è¡Œå¤„ç†å¤šä¸ªæµ
        tasks = []
        for name, processor in processors.items():
            stream = get_audio_stream(name)  # è·å–å¯¹åº”çš„éŸ³é¢‘æµ
            task = asyncio.create_task(
                process_single_stream(name, processor, stream)
            )
            tasks.append(task)
        
        await asyncio.gather(*tasks)
        
    finally:
        # æ¸…ç†èµ„æº
        for processor in processors.values():
            await processor.close()

async def process_single_stream(name, processor, stream):
    """å¤„ç†å•ä¸ªéŸ³é¢‘æµ"""
    async for vad_result in processor.process_stream(stream):
        if vad_result.is_compensated:
            print(f"[{name}] è¯­éŸ³å¼€å§‹ï¼ˆè¡¥å¿: "
                  f"{vad_result.original_start_ms - vad_result.start_ms:.0f}msï¼‰")
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åˆç†é€‰æ‹©è¡¥å¿æ—¶é•¿

```python
# æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„è¡¥å¿æ—¶é•¿
COMPENSATION_PRESETS = {
    "real_time_chat": 300,      # å®æ—¶èŠå¤©ï¼Œä¼˜å…ˆå“åº”é€Ÿåº¦
    "voice_recording": 200,     # è¯­éŸ³å½•åˆ¶ï¼Œå¹³è¡¡å‡†ç¡®æ€§å’Œå“åº”
    "transcription": 150,       # è½¬å½•æœåŠ¡ï¼Œä¼˜å…ˆå‡†ç¡®æ€§
    "voice_commands": 250,      # è¯­éŸ³å‘½ä»¤ï¼Œå¿«é€Ÿå“åº”
    "meeting_notes": 100,       # ä¼šè®®è®°å½•ï¼Œé«˜ç²¾åº¦è¦æ±‚
}

def create_optimized_config(scenario: str):
    compensation = COMPENSATION_PRESETS.get(scenario, 200)
    return VADConfig(
        backend="silero",
        compensation_ms=compensation
    )
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–

```python
async def batch_process_with_compensation():
    """æ‰¹å¤„ç†æ¨¡å¼çš„ä¼˜åŒ–ç¤ºä¾‹"""
    
    vad_config = VADConfig(
        backend="silero",
        compensation_ms=200,
        chunk_duration_ms=1000,  # æ›´å¤§çš„å—å‡å°‘å¤„ç†é¢‘ç‡
        overlap_ms=50            # é€‚åº¦é‡å ç¡®ä¿å‡†ç¡®æ€§
    )
    
    processor = await create_vad_processor(
        AudioConfig(sample_rate=16000, channels=1),
        vad_config
    )
    
    # å¤„ç†é€»è¾‘...
```

## æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜

**é—®é¢˜**: è¡¥å¿æ•ˆæœä¸æ˜æ˜¾
```python
# è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥é…ç½®
config = VADConfig(compensation_ms=200)
print(f"è¡¥å¿è®¾ç½®: {config.compensation_ms}ms")

# éªŒè¯è¡¥å¿å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ
compensator = SimpleDelayCompensator(200)
print(f"è¡¥å¿å™¨å¯ç”¨: {compensator.is_enabled()}")
```

**é—®é¢˜**: è¿‡åº¦è¡¥å¿å¯¼è‡´æ—¶é—´æˆ³ä¸ºè´Ÿ
```python
# å†…ç½®ä¿æŠ¤æœºåˆ¶ä¼šè‡ªåŠ¨å¤„ç†
vad_result = VADResult(
    is_speech=True,
    start_ms=50.0,  # å°äºè¡¥å¿æ—¶é•¿
    end_ms=500.0,
    chunk_id=1
)

compensator = SimpleDelayCompensator(200)
result = compensator.process_result(vad_result)
print(f"è¡¥å¿åæ—¶é—´: {result.start_ms}ms")  # è¾“å‡º: 0.0ms (å·²ä¿æŠ¤)
```

### 2. è°ƒè¯•æ¨¡å¼

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—æŸ¥çœ‹è¡¥å¿è¿‡ç¨‹
import logging
logging.getLogger('cascade.processor.delay_compensator').setLevel(logging.DEBUG)

# æ£€æŸ¥è¡¥å¿ç»“æœ
def debug_compensation(vad_result):
    if vad_result.is_compensated:
        compensation = vad_result.original_start_ms - vad_result.start_ms
        print(f"ğŸ”§ è°ƒè¯•: åŸå§‹={vad_result.original_start_ms:.1f}ms, "
              f"è¡¥å¿={compensation:.1f}ms, "
              f"ç»“æœ={vad_result.start_ms:.1f}ms")
```

## æœ€ä½³å®è·µæ€»ç»“

1. **è¡¥å¿æ—¶é•¿é€‰æ‹©**: 
   - å®æ—¶åº”ç”¨: 200-300ms
   - å½•åˆ¶åº”ç”¨: 150-200ms
   - é«˜ç²¾åº¦åº”ç”¨: 100-150ms

2. **æ€§èƒ½è€ƒè™‘**:
   - è¡¥å¿åŠŸèƒ½å‡ ä¹é›¶å¼€é”€
   - ä»…åœ¨è¯­éŸ³å¼€å§‹æ—¶è¿›è¡Œæ—¶é—´æˆ³è°ƒæ•´
   - ä¸å½±å“æµå¼å¤„ç†æ€§èƒ½

3. **é›†æˆå»ºè®®**:
   - åœ¨é…ç½®é˜¶æ®µè®¾ç½®è¡¥å¿å‚æ•°
   - ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»ºå¤„ç†å™¨
   - å®šæœŸæ£€æŸ¥è¡¥å¿æ•ˆæœå¹¶è°ƒæ•´å‚æ•°

4. **ç›‘æ§æŒ‡æ ‡**:
   - è¯­éŸ³å¼€å§‹æ£€æµ‹å»¶è¿Ÿ
   - è¡¥å¿é¢‘ç‡å’Œå¹…åº¦
   - æ•´ä½“è¯†åˆ«å‡†ç¡®æ€§

é€šè¿‡åˆç†ä½¿ç”¨å»¶è¿Ÿè¡¥å¿åŠŸèƒ½ï¼Œå¯ä»¥æ˜¾è‘—æå‡VADç³»ç»Ÿçš„å®æ—¶æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚
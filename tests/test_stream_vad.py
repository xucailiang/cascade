#!/usr/bin/env python3
"""
æµå¼VADæµ‹è¯•è„šæœ¬ - æ”¯æŒä¸åŒéŸ³é¢‘å—å¤§å°æµ‹è¯•
æ¨¡æ‹ŸçœŸå®çš„æµå¼éŸ³é¢‘å¤„ç†åœºæ™¯ï¼Œæ”¯æŒè‡ªå®šä¹‰éŸ³é¢‘å—å¤§å°è¿›è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•

æ”¹é€ è¯´æ˜ï¼š
- ä½¿ç”¨æœ€æ–°çš„cascadeæ¨¡å—API
- ä½¿ç”¨cascade.Config()å’Œcascade.StreamProcessor()
- ä½¿ç”¨result.is_speech_segmentæ£€æŸ¥ç»“æœç±»å‹
- æ·»åŠ ç»Ÿè®¡ä¿¡æ¯è·å–
- ç§»é™¤stream_idå‚æ•°ï¼ˆæ–°APIä¸éœ€è¦ï¼‰
- æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šéŸ³é¢‘å—å¤§å°
- æ”¯æŒå¤šç§å—å¤§å°çš„å¯¹æ¯”æµ‹è¯•
"""

import argparse
import asyncio
import os
import time
import wave
from collections.abc import AsyncIterator
from pathlib import Path
from typing import Dict, List

import cascade


class ChunkSizeTestResult:
    """éŸ³é¢‘å—å¤§å°æµ‹è¯•ç»“æœ"""
    
    def __init__(self, chunk_size: int):
        self.chunk_size = chunk_size
        self.segment_count = 0
        self.frame_count = 0
        self.total_processing_time = 0.0
        self.average_processing_time = 0.0
        self.total_chunks_processed = 0
        self.start_time = 0.0
        self.end_time = 0.0
        
    @property
    def total_test_time(self) -> float:
        """æ€»æµ‹è¯•æ—¶é—´ï¼ˆç§’ï¼‰"""
        return self.end_time - self.start_time
        
    @property
    def throughput_chunks_per_second(self) -> float:
        """ååé‡ï¼ˆå—/ç§’ï¼‰"""
        if self.total_test_time > 0:
            return self.total_chunks_processed / self.total_test_time
        return 0.0


async def simulate_audio_stream(audio_file: str, chunk_size: int = 4096) -> AsyncIterator[bytes]:
    """
    æ¨¡æ‹ŸéŸ³é¢‘æµï¼Œå°†éŸ³é¢‘æ–‡ä»¶åˆ‡å‰²ä¸ºæŒ‡å®šå¤§å°çš„éŸ³é¢‘å—
    
    Args:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        chunk_size: éŸ³é¢‘å—å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        
    Yields:
        bytes: éŸ³é¢‘æ•°æ®å—
    """
    print(f"ğŸ“¡ å¼€å§‹æ¨¡æ‹ŸéŸ³é¢‘æµ: {audio_file}")
    print(f"ğŸ”§ éŸ³é¢‘å—å¤§å°: {chunk_size} å­—èŠ‚")

    try:
        with wave.open(audio_file, 'rb') as wav_file:
            # è·å–éŸ³é¢‘ä¿¡æ¯
            channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            framerate = wav_file.getframerate()
            total_frames = wav_file.getnframes()

            print("ğŸµ éŸ³é¢‘ä¿¡æ¯:")
            print(f"   - å£°é“æ•°: {channels}")
            print(f"   - é‡‡æ ·ä½æ·±: {sample_width * 8} bit")
            print(f"   - é‡‡æ ·ç‡: {framerate} Hz")
            print(f"   - æ€»å¸§æ•°: {total_frames}")
            print(f"   - æ—¶é•¿: {total_frames / framerate:.2f} ç§’")

            chunk_count = 0
            total_bytes = 0

            # é€å—è¯»å–éŸ³é¢‘æ•°æ®
            while True:
                audio_chunk = wav_file.readframes(chunk_size // (channels * sample_width))
                if not audio_chunk:
                    break

                chunk_count += 1
                total_bytes += len(audio_chunk)

                print(f"ğŸ“¦ å‘é€éŸ³é¢‘å— {chunk_count}: {len(audio_chunk)} å­—èŠ‚", end="\r")

                # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
                await asyncio.sleep(0.01)

                yield audio_chunk

            print(f"\nâœ… éŸ³é¢‘æµæ¨¡æ‹Ÿå®Œæˆ: {chunk_count} ä¸ªéŸ³é¢‘å—, æ€»è®¡ {total_bytes} å­—èŠ‚")

    except Exception as e:
        print(f"âŒ éŸ³é¢‘æµæ¨¡æ‹Ÿå¤±è´¥: {e}")


async def test_stream_vad_processing(audio_file: str, chunk_size: int = 4096, save_segments: bool = True) -> ChunkSizeTestResult:
    """
    æµ‹è¯•æµå¼VADå¤„ç†
    
    Args:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        chunk_size: éŸ³é¢‘å—å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        save_segments: æ˜¯å¦ä¿å­˜è¯­éŸ³æ®µæ–‡ä»¶
        
    Returns:
        ChunkSizeTestResult: æµ‹è¯•ç»“æœ
    """
    print(f"ğŸ¯ å¼€å§‹æµå¼VADæµ‹è¯•: {audio_file} (å—å¤§å°: {chunk_size})")

    if not os.path.exists(audio_file):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return ChunkSizeTestResult(chunk_size)

    # åˆ›å»ºæµ‹è¯•ç»“æœå¯¹è±¡
    test_result = ChunkSizeTestResult(chunk_size)
    test_result.start_time = time.time()

    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆä»…åœ¨ä¿å­˜è¯­éŸ³æ®µæ—¶ï¼‰
    output_dir = None
    if save_segments:
        output_dir = Path(f"stream_speech_segments_{chunk_size}")
        output_dir.mkdir(exist_ok=True)

    try:
        # åˆ›å»ºé…ç½®
        config = cascade.Config(
            vad_threshold=0.5,
            min_silence_duration_ms=500,
            speech_pad_ms=300
        )
        
        # ä½¿ç”¨StreamProcessorè¿›è¡Œæµå¼å¤„ç†
        async with cascade.StreamProcessor(config) as processor:
            print("ğŸš€ StreamProcessor å·²å¯åŠ¨")

            # æ¨¡æ‹ŸéŸ³é¢‘æµå¹¶å¤„ç†
            audio_stream = simulate_audio_stream(audio_file, chunk_size=chunk_size)

            async for result in processor.process_stream(audio_stream):
                if result.is_speech_segment and result.segment:
                    test_result.segment_count += 1
                    segment = result.segment

                    start_ms = int(segment.start_timestamp_ms)
                    end_ms = int(segment.end_timestamp_ms)
                    duration_ms = int(segment.duration_ms)

                    print(f"\nğŸ¤ è¯­éŸ³æ®µ {test_result.segment_count}: {start_ms}ms - {end_ms}ms (æ—¶é•¿: {duration_ms}ms)")

                    # ä¿å­˜è¯­éŸ³æ®µä¸ºWAVæ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if save_segments and output_dir:
                        output_file = output_dir / f"stream_speech_segment_{test_result.segment_count}_{start_ms}ms-{end_ms}ms.wav"
                        await save_audio_segment(segment.audio_data, output_file)
                        print(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")

                elif result.frame:
                    # å•å¸§ç»“æœ
                    test_result.frame_count += 1
                    frame = result.frame
                    if test_result.frame_count % 50 == 0:  # æ¯50å¸§æ‰“å°ä¸€æ¬¡
                        print(f"ğŸ”‡ å•å¸§ {test_result.frame_count}: {frame.timestamp_ms:.0f}ms", end="\r")

            # è·å–å¤„ç†ç»Ÿè®¡
            stats = processor.get_stats()
            test_result.total_chunks_processed = stats.total_chunks_processed
            test_result.total_processing_time = stats.total_processing_time_ms
            test_result.average_processing_time = stats.average_processing_time_ms
            
            test_result.end_time = time.time()

            print("\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"   - æ€»ç»“æœ: {test_result.segment_count + test_result.frame_count} ä¸ª")
            print(f"   - è¯­éŸ³æ®µ: {test_result.segment_count} ä¸ª")
            print(f"   - å•å¸§: {test_result.frame_count} ä¸ª")
            print(f"   - æ€»å¤„ç†å—: {test_result.total_chunks_processed}")
            print(f"   - å¹³å‡å¤„ç†æ—¶é—´: {test_result.average_processing_time:.2f}ms")
            print(f"   - æ€»æµ‹è¯•æ—¶é—´: {test_result.total_test_time:.2f}s")
            print(f"   - ååé‡: {test_result.throughput_chunks_per_second:.2f} å—/ç§’")

    except Exception as e:
        print(f"âŒ æµå¼å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        test_result.end_time = time.time()
        return test_result

    print("\nâœ… æµå¼VADæµ‹è¯•å®Œæˆï¼")
    if save_segments and test_result.segment_count > 0 and output_dir:
        print(f"ğŸ“ è¯­éŸ³æ®µå·²ä¿å­˜åˆ°: {output_dir.absolute()}")
    
    return test_result


async def save_audio_segment(audio_data: bytes, output_file: Path):
    """
    ä¿å­˜éŸ³é¢‘æ®µä¸ºWAVæ–‡ä»¶
    
    Args:
        audio_data: éŸ³é¢‘æ•°æ®ï¼ˆ16kHz, 16bit, monoï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        with wave.open(str(output_file), 'wb') as wav_file:
            # Silero VADè¦æ±‚çš„éŸ³é¢‘æ ¼å¼
            wav_file.setnchannels(1)      # å•å£°é“
            wav_file.setsampwidth(2)      # 16ä½
            wav_file.setframerate(16000)  # 16kHzé‡‡æ ·ç‡
            wav_file.writeframes(audio_data)
    except Exception as e:
        print(f"âŒ ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥ {output_file}: {e}")


async def run_chunk_size_comparison(audio_file: str, chunk_sizes: List[int]) -> Dict[int, ChunkSizeTestResult]:
    """
    è¿è¡Œä¸åŒéŸ³é¢‘å—å¤§å°çš„å¯¹æ¯”æµ‹è¯•
    
    Args:
        audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        chunk_sizes: è¦æµ‹è¯•çš„éŸ³é¢‘å—å¤§å°åˆ—è¡¨
        
    Returns:
        Dict[int, ChunkSizeTestResult]: æµ‹è¯•ç»“æœå­—å…¸ï¼Œé”®ä¸ºå—å¤§å°
    """
    print("ğŸ”¬ å¼€å§‹éŸ³é¢‘å—å¤§å°å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    results = {}
    
    for i, chunk_size in enumerate(chunk_sizes):
        print(f"\nğŸ“Š æµ‹è¯• {i+1}/{len(chunk_sizes)}: å—å¤§å° {chunk_size} å­—èŠ‚")
        print("-" * 40)
        
        # è¿è¡Œæµ‹è¯•ï¼ˆé™¤äº†ç¬¬ä¸€ä¸ªæµ‹è¯•ï¼Œå…¶ä»–ä¸ä¿å­˜è¯­éŸ³æ®µæ–‡ä»¶ä»¥èŠ‚çœç©ºé—´ï¼‰
        save_segments = (i == 0)
        result = await test_stream_vad_processing(audio_file, chunk_size, save_segments)
        results[chunk_size] = result
        
        # ç®€çŸ­çš„ç»“æœæ‘˜è¦
        print(f"âœ… å®Œæˆ: {result.segment_count}æ®µ, {result.total_chunks_processed}å—, "
              f"{result.average_processing_time:.2f}ms/å—, {result.throughput_chunks_per_second:.1f}å—/ç§’")
    
    return results


def print_comparison_results(results: Dict[int, ChunkSizeTestResult]):
    """
    æ‰“å°å¯¹æ¯”æµ‹è¯•ç»“æœ
    
    Args:
        results: æµ‹è¯•ç»“æœå­—å…¸
    """
    print("\n" + "=" * 80)
    print("ğŸ“ˆ éŸ³é¢‘å—å¤§å°å¯¹æ¯”æµ‹è¯•ç»“æœ")
    print("=" * 80)
    
    # è¡¨å¤´
    print(f"{'å—å¤§å°(å­—èŠ‚)':<12} {'è¯­éŸ³æ®µ':<8} {'æ€»å—æ•°':<8} {'å¹³å‡å¤„ç†æ—¶é—´(ms)':<16} {'ååé‡(å—/ç§’)':<14} {'æ€»æµ‹è¯•æ—¶é—´(s)':<14}")
    print("-" * 80)
    
    # æŒ‰å—å¤§å°æ’åºæ˜¾ç¤ºç»“æœ
    for chunk_size in sorted(results.keys()):
        result = results[chunk_size]
        print(f"{chunk_size:<12} {result.segment_count:<8} {result.total_chunks_processed:<8} "
              f"{result.average_processing_time:<16.2f} {result.throughput_chunks_per_second:<14.1f} "
              f"{result.total_test_time:<14.2f}")
    
    # æ€§èƒ½åˆ†æ
    print("\nğŸ“Š æ€§èƒ½åˆ†æ:")
    
    # æ‰¾å‡ºæœ€å¿«å’Œæœ€æ…¢çš„é…ç½®
    fastest_chunk_size = min(results.keys(), key=lambda x: results[x].average_processing_time)
    slowest_chunk_size = max(results.keys(), key=lambda x: results[x].average_processing_time)
    
    fastest_result = results[fastest_chunk_size]
    slowest_result = results[slowest_chunk_size]
    
    print(f"ğŸš€ æœ€å¿«å¤„ç†: {fastest_chunk_size}å­—èŠ‚ ({fastest_result.average_processing_time:.2f}ms/å—)")
    print(f"ğŸŒ æœ€æ…¢å¤„ç†: {slowest_chunk_size}å­—èŠ‚ ({slowest_result.average_processing_time:.2f}ms/å—)")
    
    # ååé‡å¯¹æ¯”
    highest_throughput_chunk_size = max(results.keys(), key=lambda x: results[x].throughput_chunks_per_second)
    lowest_throughput_chunk_size = min(results.keys(), key=lambda x: results[x].throughput_chunks_per_second)
    
    print(f"ğŸ“ˆ æœ€é«˜ååé‡: {highest_throughput_chunk_size}å­—èŠ‚ ({results[highest_throughput_chunk_size].throughput_chunks_per_second:.1f}å—/ç§’)")
    print(f"ğŸ“‰ æœ€ä½ååé‡: {lowest_throughput_chunk_size}å­—èŠ‚ ({results[lowest_throughput_chunk_size].throughput_chunks_per_second:.1f}å—/ç§’)")
    
    # å»ºè®®
    print(f"\nğŸ’¡ å»ºè®®:")
    if fastest_chunk_size == highest_throughput_chunk_size:
        print(f"   æ¨èä½¿ç”¨ {fastest_chunk_size} å­—èŠ‚å—å¤§å°ï¼Œå…¼é¡¾å¤„ç†é€Ÿåº¦å’Œååé‡")
    else:
        print(f"   ä½å»¶è¿Ÿåœºæ™¯æ¨è: {fastest_chunk_size} å­—èŠ‚")
        print(f"   é«˜ååé‡åœºæ™¯æ¨è: {highest_throughput_chunk_size} å­—èŠ‚")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Cascade æµå¼VADæµ‹è¯• - æ”¯æŒä¸åŒéŸ³é¢‘å—å¤§å°æµ‹è¯•")
    
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=4096,
        help="éŸ³é¢‘å—å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œé»˜è®¤4096"
    )
    
    parser.add_argument(
        "--compare",
        action="store_true",
        help="è¿è¡Œå¤šç§å—å¤§å°çš„å¯¹æ¯”æµ‹è¯•"
    )
    
    parser.add_argument(
        "--chunk-sizes",
        type=str,
        default="1024,2048,4096,8192,16384",
        help="å¯¹æ¯”æµ‹è¯•çš„å—å¤§å°åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œé»˜è®¤: 1024,2048,4096,8192,16384"
    )
    
    parser.add_argument(
        "--audio-file",
        type=str,
        help="æŒ‡å®šéŸ³é¢‘æ–‡ä»¶è·¯å¾„"
    )
    
    return parser.parse_args()


async def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("ğŸŒŠ Cascade æµå¼VAD æµ‹è¯•")
    print("=" * 50)

    # ç¡®å®šéŸ³é¢‘æ–‡ä»¶
    audio_file = args.audio_file
    if not audio_file:
        # æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
        test_files = [
            "æˆ‘ç°åœ¨å¼€å§‹å½•éŸ³ï¼Œç†è®ºä¸Šä¼šæœ‰ä¸¤ä¸ªæ–‡ä»¶.wav"
        ]
        
        # å¯»æ‰¾å¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶
        for file_path in test_files:
            if os.path.exists(file_path):
                audio_file = file_path
                break

    if not audio_file or not os.path.exists(audio_file):
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶")
        if not args.audio_file:
            print("è¯·å°†éŸ³é¢‘æ–‡ä»¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼Œæ”¯æŒçš„æ–‡ä»¶å:")
            test_files = [
                "æˆ‘ç°åœ¨å¼€å§‹å½•éŸ³ï¼Œç†è®ºä¸Šä¼šæœ‰ä¸¤ä¸ªæ–‡ä»¶.wav"
            ]
            for file_path in test_files:
                print(f"  - {file_path}")
        print("\nğŸ’¡ æç¤º: éŸ³é¢‘æ–‡ä»¶åº”ä¸ºWAVæ ¼å¼ï¼Œå»ºè®®16kHzé‡‡æ ·ç‡")
        print("ğŸ’¡ æˆ–è€…ä½¿ç”¨ --audio-file å‚æ•°æŒ‡å®šéŸ³é¢‘æ–‡ä»¶è·¯å¾„")
        return

    if args.compare:
        # å¯¹æ¯”æµ‹è¯•æ¨¡å¼
        try:
            chunk_sizes = [int(x.strip()) for x in args.chunk_sizes.split(",")]
        except ValueError:
            print("âŒ å—å¤§å°åˆ—è¡¨æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨é€—å·åˆ†éš”çš„æ•´æ•°")
            return
            
        print(f"ğŸ¯ å¯¹æ¯”æµ‹è¯•æ¨¡å¼: {chunk_sizes}")
        results = await run_chunk_size_comparison(audio_file, chunk_sizes)
        print_comparison_results(results)
    else:
        # å•ä¸€æµ‹è¯•æ¨¡å¼
        print(f"ğŸ¯ å•ä¸€æµ‹è¯•æ¨¡å¼: å—å¤§å° {args.chunk_size} å­—èŠ‚")
        await test_stream_vad_processing(audio_file, args.chunk_size, save_segments=True)


if __name__ == "__main__":
    asyncio.run(main())

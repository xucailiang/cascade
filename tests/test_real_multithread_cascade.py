#!/usr/bin/env python3
"""
çœŸæ­£çš„å¤šçº¿ç¨‹å¤šCascadeInstanceå®ä¾‹æµ‹è¯•è„šæœ¬

ä½¿ç”¨ThreadPoolExecutorå®ç°çœŸæ­£çš„å¤šçº¿ç¨‹å¹¶å‘æµ‹è¯•ï¼Œ
éªŒè¯æ¯ä¸ªçº¿ç¨‹è¿è¡Œç‹¬ç«‹çš„CascadeInstanceå®ä¾‹çš„æµå¼éŸ³é¢‘å¤„ç†èƒ½åŠ›ã€‚

æ”¹è¿›ç‚¹ï¼š
1. ä½¿ç”¨çœŸæ­£çš„å¤šçº¿ç¨‹è€Œä¸æ˜¯å¼‚æ­¥å¹¶å‘
2. ä»æ¨¡å‹åŠ è½½å®Œæˆåå¼€å§‹è®¡æ—¶
3. ç§»é™¤äººå·¥å»¶è¿Ÿ
4. ä¼˜åŒ–æ€§èƒ½æµ‹è¯•é€»è¾‘
"""

import logging
import os
import threading
import time
import wave
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, List

from cascade.stream import StreamProcessor, Config
from pydantic import BaseModel, Field

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(threadName)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ThreadTestResult(BaseModel):
    """çº¿ç¨‹æµ‹è¯•ç»“æœ"""
    thread_id: int = Field(description="çº¿ç¨‹ID")
    thread_name: str = Field(description="çº¿ç¨‹åç§°")
    stream_id: str = Field(description="æµæ ‡è¯†ç¬¦")
    instance_id: str = Field(description="CascadeInstance ID")
    
    # å¤„ç†ç»Ÿè®¡
    total_chunks_processed: int = Field(default=0, description="æ€»å¤„ç†å—æ•°")
    speech_segments_count: int = Field(default=0, description="è¯­éŸ³æ®µæ•°é‡")
    single_frames_count: int = Field(default=0, description="å•å¸§æ•°é‡")
    
    # æ—¶é—´ç»Ÿè®¡ï¼ˆæ’é™¤æ¨¡å‹åŠ è½½æ—¶é—´ï¼‰
    model_load_time_ms: float = Field(default=0.0, description="æ¨¡å‹åŠ è½½æ—¶é—´(ms)")
    processing_start_time: float = Field(description="å¤„ç†å¼€å§‹æ—¶é—´")
    processing_end_time: float = Field(default=0.0, description="å¤„ç†ç»“æŸæ—¶é—´")
    pure_processing_time_ms: float = Field(default=0.0, description="çº¯å¤„ç†æ—¶é—´(ms)")
    
    # æ€§èƒ½ç»Ÿè®¡
    throughput_chunks_per_sec: float = Field(default=0.0, description="ååé‡(å—/ç§’)")
    
    # é”™è¯¯ç»Ÿè®¡
    error_count: int = Field(default=0, description="é”™è¯¯æ¬¡æ•°")
    
    def calculate_metrics(self):
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆæ’é™¤æ¨¡å‹åŠ è½½æ—¶é—´ï¼‰"""
        self.pure_processing_time_ms = (self.processing_end_time - self.processing_start_time) * 1000
        
        if self.pure_processing_time_ms > 0:
            self.throughput_chunks_per_sec = (
                self.total_chunks_processed / (self.pure_processing_time_ms / 1000)
            )


class RealMultithreadTestSuite:
    """çœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, audio_file: str, num_threads: int = 4, chunk_size: int = 4096):
        """
        åˆå§‹åŒ–æµ‹è¯•å¥—ä»¶
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            num_threads: çº¿ç¨‹æ•°é‡
            chunk_size: éŸ³é¢‘å—å¤§å°
        """
        self.audio_file = audio_file
        self.num_threads = num_threads
        self.chunk_size = chunk_size
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path("real_multithread_test_results")
        self.output_dir.mkdir(exist_ok=True)
        
        # é¢„åŠ è½½éŸ³é¢‘æ•°æ®ï¼ˆæ‰€æœ‰çº¿ç¨‹å…±äº«ï¼‰
        self.audio_chunks = self._preload_audio_chunks()
        
        # æµ‹è¯•ç»“æœå­˜å‚¨
        self.thread_results: Dict[int, ThreadTestResult] = {}
        self.thread_lock = threading.RLock()

    def _preload_audio_chunks(self) -> List[bytes]:
        """é¢„åŠ è½½éŸ³é¢‘æ•°æ®ä¸ºå—åˆ—è¡¨"""
        logger.info(f"é¢„åŠ è½½éŸ³é¢‘æ–‡ä»¶: {self.audio_file}")
        
        chunks = []
        try:
            with wave.open(self.audio_file, 'rb') as wav_file:
                # è·å–éŸ³é¢‘ä¿¡æ¯
                channels = wav_file.getnchannels()
                sample_width = wav_file.getsampwidth()
                framerate = wav_file.getframerate()
                total_frames = wav_file.getnframes()
                
                logger.info(f"éŸ³é¢‘ä¿¡æ¯: {channels}ch, {sample_width*8}bit, {framerate}Hz, {total_frames} å¸§")
                
                # é€å—è¯»å–éŸ³é¢‘æ•°æ®
                while True:
                    frames_per_chunk = self.chunk_size // (channels * sample_width)
                    audio_chunk = wav_file.readframes(frames_per_chunk)
                    if not audio_chunk:
                        break
                    chunks.append(audio_chunk)
                
                logger.info(f"é¢„åŠ è½½å®Œæˆ: {len(chunks)} ä¸ªéŸ³é¢‘å—")
                
        except Exception as e:
            logger.error(f"é¢„åŠ è½½éŸ³é¢‘å¤±è´¥: {e}")
            
        return chunks

    def process_audio_in_thread(self, thread_id: int) -> ThreadTestResult:
        """
        åœ¨æŒ‡å®šçº¿ç¨‹ä¸­å¤„ç†éŸ³é¢‘ï¼ˆåŒæ­¥å‡½æ•°ï¼Œç”¨äºThreadPoolExecutorï¼‰
        
        Args:
            thread_id: çº¿ç¨‹ID
            
        Returns:
            ThreadTestResult: çº¿ç¨‹å¤„ç†ç»“æœ
        """
        thread_name = threading.current_thread().name
        # åŸºäºçº¿ç¨‹IDå’Œçº¿ç¨‹åç”Ÿæˆå”¯ä¸€çš„stream_id
        stream_id = f"thread_{thread_id}_{threading.get_ident()}"
        
        logger.info(f"çº¿ç¨‹ {thread_id} ({thread_name}) å¼€å§‹å¤„ç†ï¼Œstream_id: {stream_id}")
        
        # åˆå§‹åŒ–ç»“æœå¯¹è±¡
        result = ThreadTestResult(
            thread_id=thread_id,
            thread_name=thread_name,
            stream_id=stream_id,
            instance_id="",
            processing_start_time=0.0  # ç¨åè®¾ç½®
        )
        
        segment_count = 0
        frame_count = 0
        
        try:
            # 1. æ¨¡å‹åŠ è½½é˜¶æ®µï¼ˆè®¡æ—¶ï¼‰
            model_load_start = time.time()
            
            # åˆ›å»ºç‹¬ç«‹çš„StreamProcessoré…ç½®
            config = Config(max_instances=1)  # æ¯ä¸ªçº¿ç¨‹åªéœ€è¦1ä¸ªå®ä¾‹
            
            # åˆ›å»ºStreamProcessorï¼ˆè¿™é‡Œä¼šåŠ è½½æ¨¡å‹ï¼‰
            processor = StreamProcessor(config)
            
            # å¯åŠ¨processorï¼ˆå®Œæˆæ¨¡å‹åˆå§‹åŒ–ï¼‰
            import asyncio
            
            # åœ¨æ–°çº¿ç¨‹ä¸­éœ€è¦åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                # å¯åŠ¨å¤„ç†å™¨
                loop.run_until_complete(processor.start())
                
                # æ¨¡å‹åŠ è½½å®Œæˆ
                model_load_end = time.time()
                result.model_load_time_ms = (model_load_end - model_load_start) * 1000
                
                logger.info(f"çº¿ç¨‹ {thread_id} æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {result.model_load_time_ms:.1f}ms")
                
                # 2. éŸ³é¢‘å¤„ç†é˜¶æ®µï¼ˆä»è¿™é‡Œå¼€å§‹è®¡æ—¶ï¼‰
                result.processing_start_time = time.time()
                
                # å®šä¹‰å¼‚æ­¥å¤„ç†å‡½æ•°
                async def process_audio_stream():
                    nonlocal segment_count, frame_count
                    
                    # åˆ›å»ºå¼‚æ­¥éŸ³é¢‘æµç”Ÿæˆå™¨ï¼ˆç”¨äºprocess_streamï¼‰
                    async def audio_stream_generator():
                        for audio_chunk in self.audio_chunks:
                            if audio_chunk:
                                yield audio_chunk
                    
                    # ä½¿ç”¨process_stream APIï¼ˆæ”¯æŒstream_idéš”ç¦»ï¼‰
                    audio_stream = audio_stream_generator()
                    
                    async for cascade_result in processor.process_stream(audio_stream, stream_id=stream_id):
                        if cascade_result.result_type == "segment" and cascade_result.segment:
                            segment_count += 1
                            segment = cascade_result.segment
                            
                            # è®°å½•å®ä¾‹ID
                            if not result.instance_id:
                                result.instance_id = cascade_result.instance_id
                            
                            start_ms = segment.start_timestamp_ms
                            end_ms = segment.end_timestamp_ms
                            duration_ms = segment.duration_ms
                            
                            logger.info(f"çº¿ç¨‹ {thread_id} è¯­éŸ³æ®µ {segment_count}: {start_ms:.0f}ms-{end_ms:.0f}ms ({duration_ms:.0f}ms)")
                            
                            # ä¿å­˜è¯­éŸ³æ®µ
                            self._save_segment_for_thread(thread_id, segment_count, segment)
                            
                        elif cascade_result.result_type == "frame":
                            frame_count += 1
                            if not result.instance_id:
                                result.instance_id = cascade_result.instance_id
                
                # è¿è¡Œå¼‚æ­¥å¤„ç†
                loop.run_until_complete(process_audio_stream())
                
                # è·å–å¤„ç†å™¨ç»Ÿè®¡ä¿¡æ¯
                stats = processor.get_stats()
                result.total_chunks_processed = stats.total_chunks_processed
                
                logger.info(f"çº¿ç¨‹ {thread_id} å¤„ç†å®Œæˆ: {segment_count} è¯­éŸ³æ®µ, {frame_count} å•å¸§")
                
                # åœæ­¢å¤„ç†å™¨
                loop.run_until_complete(processor.stop())
                
            finally:
                loop.close()
                
        except Exception as e:
            result.error_count += 1
            logger.error(f"çº¿ç¨‹ {thread_id} å¤„ç†å¤±è´¥: {e}")
        
        finally:
            result.processing_end_time = time.time()
            result.speech_segments_count = segment_count
            result.single_frames_count = frame_count
            result.calculate_metrics()
            
            # çº¿ç¨‹å®‰å…¨åœ°å­˜å‚¨ç»“æœ
            with self.thread_lock:
                self.thread_results[thread_id] = result
        
        return result

    def _save_segment_for_thread(self, thread_id: int, segment_count: int, segment):
        """ä¸ºæŒ‡å®šçº¿ç¨‹ä¿å­˜è¯­éŸ³æ®µ"""
        try:
            thread_dir = self.output_dir / f"thread_{thread_id}"
            thread_dir.mkdir(exist_ok=True)
            
            start_ms = segment.start_timestamp_ms
            end_ms = segment.end_timestamp_ms
            output_file = thread_dir / f"segment_{segment_count}_{start_ms:.0f}ms-{end_ms:.0f}ms.wav"
            
            with wave.open(str(output_file), 'wb') as wav_file:
                wav_file.setnchannels(1)      # å•å£°é“
                wav_file.setsampwidth(2)      # 16ä½
                wav_file.setframerate(16000)  # 16kHzé‡‡æ ·ç‡
                wav_file.writeframes(segment.audio_data)
                
        except Exception as e:
            logger.error(f"çº¿ç¨‹ {thread_id} ä¿å­˜è¯­éŸ³æ®µå¤±è´¥: {e}")

    def run_real_multithread_test(self) -> Dict[int, ThreadTestResult]:
        """
        è¿è¡ŒçœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•
        
        Returns:
            Dict[int, ThreadTestResult]: å„çº¿ç¨‹çš„æµ‹è¯•ç»“æœ
        """
        logger.info(f"å¼€å§‹çœŸæ­£çš„å¤šçº¿ç¨‹å¹¶å‘æµ‹è¯•: {self.num_threads} ä¸ªçº¿ç¨‹")
        logger.info(f"éŸ³é¢‘æ–‡ä»¶: {self.audio_file}")
        logger.info(f"éŸ³é¢‘å—æ•°é‡: {len(self.audio_chunks)}")
        logger.info(f"å—å¤§å°: {self.chunk_size} å­—èŠ‚")
        
        # ä½¿ç”¨ThreadPoolExecutoråˆ›å»ºçœŸæ­£çš„å¤šçº¿ç¨‹
        with ThreadPoolExecutor(max_workers=self.num_threads, thread_name_prefix="AudioProcessor") as executor:
            # æäº¤æ‰€æœ‰çº¿ç¨‹ä»»åŠ¡
            future_to_thread_id = {}
            for thread_id in range(1, self.num_threads + 1):
                future = executor.submit(self.process_audio_in_thread, thread_id)
                future_to_thread_id[future] = thread_id
            
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            successful_results = {}
            for future in as_completed(future_to_thread_id):
                thread_id = future_to_thread_id[future]
                try:
                    result = future.result()
                    successful_results[thread_id] = result
                    logger.info(f"çº¿ç¨‹ {thread_id} å®Œæˆå¤„ç†")
                except Exception as exc:
                    logger.error(f"çº¿ç¨‹ {thread_id} æ‰§è¡Œå¼‚å¸¸: {exc}")
        
        return successful_results

    def analyze_results(self, results: Dict[int, ThreadTestResult]):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š çœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•ç»“æœåˆ†æ")
        logger.info("=" * 60)
        
        if not results:
            logger.warning("æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ")
            return
        
        # å®ä¾‹éš”ç¦»æ€§éªŒè¯
        instance_ids = [result.instance_id for result in results.values()]
        unique_instances = set(instance_ids)
        
        logger.info(f"ğŸ” çº¿ç¨‹éš”ç¦»æ€§æ£€æŸ¥:")
        logger.info(f"   - çº¿ç¨‹æ•°é‡: {len(results)}")
        logger.info(f"   - å®ä¾‹IDæ•°é‡: {len(unique_instances)}")
        logger.info(f"   - å®ä¾‹éš”ç¦»: {'âœ… æˆåŠŸ' if len(unique_instances) == len(results) else 'âŒ å¤±è´¥'}")
        
        # æ˜¾ç¤ºå„çº¿ç¨‹è¯¦ç»†ç»“æœ
        logger.info(f"\nğŸ“ˆ å„çº¿ç¨‹å¤„ç†ç»“æœ:")
        total_segments = 0
        total_frames = 0
        total_errors = 0
        total_model_load_time = 0.0
        total_processing_time = 0.0
        
        for thread_id, result in results.items():
            logger.info(f"   çº¿ç¨‹ {thread_id} ({result.thread_name}):")
            logger.info(f"     - å®ä¾‹ID: {result.instance_id}")
            logger.info(f"     - è¯­éŸ³æ®µ: {result.speech_segments_count}")
            logger.info(f"     - å•å¸§: {result.single_frames_count}")
            logger.info(f"     - æ¨¡å‹åŠ è½½æ—¶é—´: {result.model_load_time_ms:.1f}ms")
            logger.info(f"     - çº¯å¤„ç†æ—¶é—´: {result.pure_processing_time_ms:.1f}ms")
            logger.info(f"     - ååé‡: {result.throughput_chunks_per_sec:.1f} å—/ç§’")
            logger.info(f"     - é”™è¯¯æ•°: {result.error_count}")
            
            total_segments += result.speech_segments_count
            total_frames += result.single_frames_count
            total_errors += result.error_count
            total_model_load_time += result.model_load_time_ms
            total_processing_time += result.pure_processing_time_ms
        
        # æ±‡æ€»ç»Ÿè®¡
        avg_model_load_time = total_model_load_time / len(results)
        avg_processing_time = total_processing_time / len(results)
        avg_throughput = sum(r.throughput_chunks_per_sec for r in results.values()) / len(results)
        
        logger.info(f"\nğŸ“‹ æ±‡æ€»ç»Ÿè®¡:")
        logger.info(f"   - æ€»è¯­éŸ³æ®µ: {total_segments}")
        logger.info(f"   - æ€»å•å¸§: {total_frames}")
        logger.info(f"   - æ€»é”™è¯¯: {total_errors}")
        logger.info(f"   - å¹³å‡æ¨¡å‹åŠ è½½æ—¶é—´: {avg_model_load_time:.1f}ms")
        logger.info(f"   - å¹³å‡çº¯å¤„ç†æ—¶é—´: {avg_processing_time:.1f}ms")
        logger.info(f"   - å¹³å‡ååé‡: {avg_throughput:.1f} å—/ç§’")
        logger.info(f"   - ç»“æœè¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
        
        # æ€§èƒ½ä¸€è‡´æ€§æ£€æŸ¥
        processing_times = [r.pure_processing_time_ms for r in results.values()]
        time_variance = max(processing_times) - min(processing_times)
        logger.info(f"\nâš¡ æ€§èƒ½ä¸€è‡´æ€§:")
        logger.info(f"   - å¤„ç†æ—¶é•¿å·®å¼‚: {time_variance:.1f}ms")
        logger.info(f"   - ä¸€è‡´æ€§è¯„ä¼°: {'âœ… è‰¯å¥½' if time_variance < 1000 else 'âš ï¸ éœ€å…³æ³¨'}")
        
        # çº¿ç¨‹çœŸå®æ€§éªŒè¯
        thread_names = [result.thread_name for result in results.values()]
        unique_thread_names = set(thread_names)
        logger.info(f"\nğŸ§µ çº¿ç¨‹çœŸå®æ€§éªŒè¯:")
        logger.info(f"   - çº¿ç¨‹åç§°æ•°é‡: {len(unique_thread_names)}")
        logger.info(f"   - çœŸå®å¤šçº¿ç¨‹: {'âœ… æ˜¯' if len(unique_thread_names) == len(results) else 'âŒ å¦'}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§µ Cascade çœŸæ­£çš„å¤šçº¿ç¨‹å¤šå®ä¾‹æµ‹è¯•")
    print("=" * 50)
    
    # éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    audio_file = "/home/justin/workspace/cascade/æˆ‘ç°åœ¨å¼€å§‹å½•éŸ³ï¼Œç†è®ºä¸Šä¼šæœ‰ä¸¤ä¸ªæ–‡ä»¶.wav"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(audio_file):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return
    
    # æµ‹è¯•é…ç½®
    num_threads = 4  # ä½¿ç”¨4ä¸ªçº¿ç¨‹æµ‹è¯•
    chunk_size = 4096  # 4KBå—å¤§å°
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = RealMultithreadTestSuite(
        audio_file=audio_file,
        num_threads=num_threads,
        chunk_size=chunk_size
    )
    
    try:
        # è¿è¡ŒçœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•
        start_time = time.time()
        results = test_suite.run_real_multithread_test()
        end_time = time.time()
        
        # åˆ†æç»“æœ
        test_suite.analyze_results(results)
        
        # æ€»ä½“æµ‹è¯•ç»“æœ
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {(end_time - start_time):.2f} ç§’")
        print(f"âœ… æˆåŠŸçº¿ç¨‹: {len(results)} / {num_threads}")
        
        if len(results) == num_threads:
            print("ğŸ† æ‰€æœ‰çº¿ç¨‹å‡æˆåŠŸå®Œæˆï¼ŒçœŸæ­£çš„å¤šçº¿ç¨‹å¤šå®ä¾‹æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†çº¿ç¨‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        logger.exception("æµ‹è¯•å¼‚å¸¸è¯¦æƒ…:")


if __name__ == "__main__":
    # æ³¨æ„ï¼šè¿™é‡Œä¸ä½¿ç”¨asyncio.runï¼Œå› ä¸ºä¸»è¦é€»è¾‘åœ¨åŒæ­¥çš„å¤šçº¿ç¨‹ä¸­
    import asyncio
    asyncio.run(main())
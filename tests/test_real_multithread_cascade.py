#!/usr/bin/env python3
"""
çœŸæ­£çš„å¤šçº¿ç¨‹å¤šStreamProcessorå®ä¾‹æµ‹è¯•è„šæœ¬

ä½¿ç”¨ThreadPoolExecutorå®ç°çœŸæ­£çš„å¤šçº¿ç¨‹å¹¶å‘æµ‹è¯•ï¼Œ
éªŒè¯æ¯ä¸ªçº¿ç¨‹è¿è¡Œç‹¬ç«‹çš„StreamProcessorå®ä¾‹çš„æµå¼éŸ³é¢‘å¤„ç†èƒ½åŠ›ã€‚

æ”¹é€ è¯´æ˜ï¼š
- ä½¿ç”¨æœ€æ–°çš„cascadeæ¨¡å—API
- ä½¿ç”¨cascade.Config()å’Œcascade.StreamProcessor()
- ä½¿ç”¨result.is_speech_segmentæ£€æŸ¥ç»“æœç±»å‹
- ç§»é™¤stream_idå‚æ•°ï¼ˆæ–°APIä¸éœ€è¦ï¼‰
- ç®€åŒ–é…ç½®åˆ›å»º

æ”¹è¿›ç‚¹ï¼š
1. ä½¿ç”¨çœŸæ­£çš„å¤šçº¿ç¨‹è€Œä¸æ˜¯å¼‚æ­¥å¹¶å‘
2. ä»æ¨¡å‹åŠ è½½å®Œæˆåå¼€å§‹è®¡æ—¶
3. ç§»é™¤äººå·¥å»¶è¿Ÿ
4. ä¼˜åŒ–æ€§èƒ½æµ‹è¯•é€»è¾‘
"""

import logging
import os
import threading
import time
import wave
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, List

import cascade
from pydantic import BaseModel, Field

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(threadName)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ThreadTestResult(BaseModel):
    """çº¿ç¨‹æµ‹è¯•ç»“æœ"""
    thread_id: int = Field(description="çº¿ç¨‹ID")
    thread_name: str = Field(description="çº¿ç¨‹åç§°")
    processor_id: str = Field(description="StreamProcessor ID")
    
    # å¤„ç†ç»Ÿè®¡
    total_chunks_processed: int = Field(default=0, description="æ€»å¤„ç†å—æ•°")
    speech_segments_count: int = Field(default=0, description="è¯­éŸ³æ®µæ•°é‡")
    single_frames_count: int = Field(default=0, description="å•å¸§æ•°é‡")
    
    # æ—¶é—´ç»Ÿè®¡ï¼ˆæ’é™¤æ¨¡å‹åŠ è½½æ—¶é—´ï¼‰
    model_load_time_ms: float = Field(default=0.0, description="æ¨¡å‹åŠ è½½æ—¶é—´(ms)")
    processing_start_time: float = Field(description="å¤„ç†å¼€å§‹æ—¶é—´")
    processing_end_time: float = Field(default=0.0, description="å¤„ç†ç»“æŸæ—¶é—´")
    pure_processing_time_ms: float = Field(default=0.0, description="çº¯å¤„ç†æ—¶é—´(ms)")
    
    # æ€§èƒ½ç»Ÿè®¡
    throughput_chunks_per_sec: float = Field(default=0.0, description="ååé‡(å—/ç§’)")
    
    # é”™è¯¯ç»Ÿè®¡
    error_count: int = Field(default=0, description="é”™è¯¯æ¬¡æ•°")
    
    def calculate_metrics(self):
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆæ’é™¤æ¨¡å‹åŠ è½½æ—¶é—´ï¼‰"""
        self.pure_processing_time_ms = (self.processing_end_time - self.processing_start_time) * 1000
        
        if self.pure_processing_time_ms > 0:
            self.throughput_chunks_per_sec = (
                self.total_chunks_processed / (self.pure_processing_time_ms / 1000)
            )


class RealMultithreadTestSuite:
    """çœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, audio_file: str, num_threads: int = 4, chunk_size: int = 4096):
        """
        åˆå§‹åŒ–æµ‹è¯•å¥—ä»¶
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            num_threads: çº¿ç¨‹æ•°é‡
            chunk_size: éŸ³é¢‘å—å¤§å°
        """
        self.audio_file = audio_file
        self.num_threads = num_threads
        self.chunk_size = chunk_size
        
        # è¾“å‡ºç›®å½•
        self.output_dir = Path("real_multithread_test_results")
        self.output_dir.mkdir(exist_ok=True)
        
        # é¢„åŠ è½½éŸ³é¢‘æ•°æ®ï¼ˆæ‰€æœ‰çº¿ç¨‹å…±äº«ï¼‰
        self.audio_chunks = self._preload_audio_chunks()
        
        # æµ‹è¯•ç»“æœå­˜å‚¨
        self.thread_results: Dict[int, ThreadTestResult] = {}
        self.thread_lock = threading.RLock()

    def _preload_audio_chunks(self) -> List[bytes]:
        """é¢„åŠ è½½éŸ³é¢‘æ•°æ®ä¸ºå—åˆ—è¡¨"""
        logger.info(f"é¢„åŠ è½½éŸ³é¢‘æ–‡ä»¶: {self.audio_file}")
        
        chunks = []
        try:
            with wave.open(self.audio_file, 'rb') as wav_file:
                # è·å–éŸ³é¢‘ä¿¡æ¯
                channels = wav_file.getnchannels()
                sample_width = wav_file.getsampwidth()
                framerate = wav_file.getframerate()
                total_frames = wav_file.getnframes()
                
                logger.info(f"éŸ³é¢‘ä¿¡æ¯: {channels}ch, {sample_width*8}bit, {framerate}Hz, {total_frames} å¸§")
                
                # é€å—è¯»å–éŸ³é¢‘æ•°æ®
                while True:
                    frames_per_chunk = self.chunk_size // (channels * sample_width)
                    audio_chunk = wav_file.readframes(frames_per_chunk)
                    if not audio_chunk:
                        break
                    chunks.append(audio_chunk)
                
                logger.info(f"é¢„åŠ è½½å®Œæˆ: {len(chunks)} ä¸ªéŸ³é¢‘å—")
                
        except Exception as e:
            logger.error(f"é¢„åŠ è½½éŸ³é¢‘å¤±è´¥: {e}")
            
        return chunks

    def process_audio_in_thread(self, thread_id: int) -> ThreadTestResult:
        """
        åœ¨æŒ‡å®šçº¿ç¨‹ä¸­å¤„ç†éŸ³é¢‘ï¼ˆåŒæ­¥å‡½æ•°ï¼Œç”¨äºThreadPoolExecutorï¼‰
        
        Args:
            thread_id: çº¿ç¨‹ID
            
        Returns:
            ThreadTestResult: çº¿ç¨‹å¤„ç†ç»“æœ
        """
        thread_name = threading.current_thread().name
        processor_id = f"processor_{thread_id}_{threading.get_ident()}"
        
        logger.info(f"çº¿ç¨‹ {thread_id} ({thread_name}) å¼€å§‹å¤„ç†ï¼Œprocessor_id: {processor_id}")
        
        # åˆå§‹åŒ–ç»“æœå¯¹è±¡
        result = ThreadTestResult(
            thread_id=thread_id,
            thread_name=thread_name,
            processor_id=processor_id,
            processing_start_time=0.0  # ç¨åè®¾ç½®
        )
        
        segment_count = 0
        frame_count = 0
        
        try:
            # 1. æ¨¡å‹åŠ è½½é˜¶æ®µï¼ˆè®¡æ—¶ï¼‰
            model_load_start = time.time()
            
            # åˆ›å»ºç‹¬ç«‹çš„StreamProcessoré…ç½®
            config = cascade.Config(
                vad_threshold=0.5,
                min_silence_duration_ms=500,
                speech_pad_ms=300
            )
            
            # åˆ›å»ºStreamProcessorï¼ˆè¿™é‡Œä¼šåŠ è½½æ¨¡å‹ï¼‰
            processor = cascade.StreamProcessor(config)
            
            # å¯åŠ¨processorï¼ˆå®Œæˆæ¨¡å‹åˆå§‹åŒ–ï¼‰
            import asyncio
            
            # åœ¨æ–°çº¿ç¨‹ä¸­éœ€è¦åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                # å®šä¹‰å¼‚æ­¥å¤„ç†å‡½æ•°
                async def process_audio_stream():
                    nonlocal segment_count, frame_count
                    
                    # ä½¿ç”¨async withå¯åŠ¨å¤„ç†å™¨
                    async with processor as proc:
                        # æ¨¡å‹åŠ è½½å®Œæˆ
                        model_load_end = time.time()
                        result.model_load_time_ms = (model_load_end - model_load_start) * 1000
                        
                        logger.info(f"çº¿ç¨‹ {thread_id} æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {result.model_load_time_ms:.1f}ms")
                        
                        # 2. éŸ³é¢‘å¤„ç†é˜¶æ®µï¼ˆä»è¿™é‡Œå¼€å§‹è®¡æ—¶ï¼‰
                        result.processing_start_time = time.time()
                        
                        # åˆ›å»ºå¼‚æ­¥éŸ³é¢‘æµç”Ÿæˆå™¨ï¼ˆç”¨äºprocess_streamï¼‰
                        async def audio_stream_generator():
                            for audio_chunk in self.audio_chunks:
                                if audio_chunk:
                                    yield audio_chunk
                        
                        # ä½¿ç”¨process_stream API
                        audio_stream = audio_stream_generator()
                        
                        async for cascade_result in proc.process_stream(audio_stream):
                            if cascade_result.is_speech_segment and cascade_result.segment:
                                segment_count += 1
                                segment = cascade_result.segment
                                
                                start_ms = int(segment.start_timestamp_ms)
                                end_ms = int(segment.end_timestamp_ms)
                                duration_ms = int(segment.duration_ms)
                                
                                logger.info(f"çº¿ç¨‹ {thread_id} è¯­éŸ³æ®µ {segment_count}: {start_ms}ms-{end_ms}ms ({duration_ms}ms)")
                                
                                # ä¿å­˜è¯­éŸ³æ®µï¼ˆåŒæ­¥è°ƒç”¨ï¼‰
                                self._save_segment_for_thread_sync(thread_id, segment_count, segment)
                                
                            elif cascade_result.frame:
                                frame_count += 1
                        
                        # è·å–å¤„ç†å™¨ç»Ÿè®¡ä¿¡æ¯
                        stats = proc.get_stats()
                        result.total_chunks_processed = stats.total_chunks_processed
                        
                        logger.info(f"çº¿ç¨‹ {thread_id} å¤„ç†å®Œæˆ: {segment_count} è¯­éŸ³æ®µ, {frame_count} å•å¸§")
                
                # è¿è¡Œå¼‚æ­¥å¤„ç†
                loop.run_until_complete(process_audio_stream())
                
            finally:
                loop.close()
                
        except Exception as e:
            result.error_count += 1
            logger.error(f"çº¿ç¨‹ {thread_id} å¤„ç†å¤±è´¥: {e}")
        
        finally:
            result.processing_end_time = time.time()
            result.speech_segments_count = segment_count
            result.single_frames_count = frame_count
            result.calculate_metrics()
            
            # çº¿ç¨‹å®‰å…¨åœ°å­˜å‚¨ç»“æœ
            with self.thread_lock:
                self.thread_results[thread_id] = result
        
        return result

    def _save_segment_for_thread_sync(self, thread_id: int, segment_count: int, segment):
        """ä¸ºæŒ‡å®šçº¿ç¨‹ä¿å­˜è¯­éŸ³æ®µï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        try:
            thread_dir = self.output_dir / f"thread_{thread_id}"
            thread_dir.mkdir(exist_ok=True)
            
            start_ms = int(segment.start_timestamp_ms)
            end_ms = int(segment.end_timestamp_ms)
            output_file = thread_dir / f"segment_{segment_count}_{start_ms}ms-{end_ms}ms.wav"
            
            with wave.open(str(output_file), 'wb') as wav_file:
                wav_file.setnchannels(1)      # å•å£°é“
                wav_file.setsampwidth(2)      # 16ä½
                wav_file.setframerate(16000)  # 16kHzé‡‡æ ·ç‡
                wav_file.writeframes(segment.audio_data)
                
        except Exception as e:
            logger.error(f"çº¿ç¨‹ {thread_id} ä¿å­˜è¯­éŸ³æ®µå¤±è´¥: {e}")

    def run_real_multithread_test(self) -> Dict[int, ThreadTestResult]:
        """
        è¿è¡ŒçœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•
        
        Returns:
            Dict[int, ThreadTestResult]: å„çº¿ç¨‹çš„æµ‹è¯•ç»“æœ
        """
        logger.info(f"å¼€å§‹çœŸæ­£çš„å¤šçº¿ç¨‹å¹¶å‘æµ‹è¯•: {self.num_threads} ä¸ªçº¿ç¨‹")
        logger.info(f"éŸ³é¢‘æ–‡ä»¶: {self.audio_file}")
        logger.info(f"éŸ³é¢‘å—æ•°é‡: {len(self.audio_chunks)}")
        logger.info(f"å—å¤§å°: {self.chunk_size} å­—èŠ‚")
        
        # ä½¿ç”¨ThreadPoolExecutoråˆ›å»ºçœŸæ­£çš„å¤šçº¿ç¨‹
        with ThreadPoolExecutor(max_workers=self.num_threads, thread_name_prefix="AudioProcessor") as executor:
            # æäº¤æ‰€æœ‰çº¿ç¨‹ä»»åŠ¡
            future_to_thread_id = {}
            for thread_id in range(1, self.num_threads + 1):
                future = executor.submit(self.process_audio_in_thread, thread_id)
                future_to_thread_id[future] = thread_id
            
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            successful_results = {}
            for future in as_completed(future_to_thread_id):
                thread_id = future_to_thread_id[future]
                try:
                    result = future.result()
                    successful_results[thread_id] = result
                    logger.info(f"çº¿ç¨‹ {thread_id} å®Œæˆå¤„ç†")
                except Exception as exc:
                    logger.error(f"çº¿ç¨‹ {thread_id} æ‰§è¡Œå¼‚å¸¸: {exc}")
        
        return successful_results

    def analyze_results(self, results: Dict[int, ThreadTestResult]):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š çœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•ç»“æœåˆ†æ")
        logger.info("=" * 60)
        
        if not results:
            logger.warning("æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ")
            return
        
        # å¤„ç†å™¨éš”ç¦»æ€§éªŒè¯
        processor_ids = [result.processor_id for result in results.values()]
        unique_processors = set(processor_ids)
        
        logger.info(f"ğŸ” çº¿ç¨‹éš”ç¦»æ€§æ£€æŸ¥:")
        logger.info(f"   - çº¿ç¨‹æ•°é‡: {len(results)}")
        logger.info(f"   - å¤„ç†å™¨IDæ•°é‡: {len(unique_processors)}")
        logger.info(f"   - å¤„ç†å™¨éš”ç¦»: {'âœ… æˆåŠŸ' if len(unique_processors) == len(results) else 'âŒ å¤±è´¥'}")
        
        # æ˜¾ç¤ºå„çº¿ç¨‹è¯¦ç»†ç»“æœ
        logger.info(f"\nğŸ“ˆ å„çº¿ç¨‹å¤„ç†ç»“æœ:")
        total_segments = 0
        total_frames = 0
        total_errors = 0
        total_model_load_time = 0.0
        total_processing_time = 0.0
        
        for thread_id, result in results.items():
            logger.info(f"   çº¿ç¨‹ {thread_id} ({result.thread_name}):")
            logger.info(f"     - å¤„ç†å™¨ID: {result.processor_id}")
            logger.info(f"     - è¯­éŸ³æ®µ: {result.speech_segments_count}")
            logger.info(f"     - å•å¸§: {result.single_frames_count}")
            logger.info(f"     - æ¨¡å‹åŠ è½½æ—¶é—´: {result.model_load_time_ms:.1f}ms")
            logger.info(f"     - çº¯å¤„ç†æ—¶é—´: {result.pure_processing_time_ms:.1f}ms")
            logger.info(f"     - ååé‡: {result.throughput_chunks_per_sec:.1f} å—/ç§’")
            logger.info(f"     - é”™è¯¯æ•°: {result.error_count}")
            
            total_segments += result.speech_segments_count
            total_frames += result.single_frames_count
            total_errors += result.error_count
            total_model_load_time += result.model_load_time_ms
            total_processing_time += result.pure_processing_time_ms
        
        # æ±‡æ€»ç»Ÿè®¡
        avg_model_load_time = total_model_load_time / len(results)
        avg_processing_time = total_processing_time / len(results)
        avg_throughput = sum(r.throughput_chunks_per_sec for r in results.values()) / len(results)
        
        logger.info(f"\nğŸ“‹ æ±‡æ€»ç»Ÿè®¡:")
        logger.info(f"   - æ€»è¯­éŸ³æ®µ: {total_segments}")
        logger.info(f"   - æ€»å•å¸§: {total_frames}")
        logger.info(f"   - æ€»é”™è¯¯: {total_errors}")
        logger.info(f"   - å¹³å‡æ¨¡å‹åŠ è½½æ—¶é—´: {avg_model_load_time:.1f}ms")
        logger.info(f"   - å¹³å‡çº¯å¤„ç†æ—¶é—´: {avg_processing_time:.1f}ms")
        logger.info(f"   - å¹³å‡ååé‡: {avg_throughput:.1f} å—/ç§’")
        logger.info(f"   - ç»“æœè¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
        
        # æ€§èƒ½ä¸€è‡´æ€§æ£€æŸ¥
        processing_times = [r.pure_processing_time_ms for r in results.values()]
        time_variance = max(processing_times) - min(processing_times)
        logger.info(f"\nâš¡ æ€§èƒ½ä¸€è‡´æ€§:")
        logger.info(f"   - å¤„ç†æ—¶é•¿å·®å¼‚: {time_variance:.1f}ms")
        logger.info(f"   - ä¸€è‡´æ€§è¯„ä¼°: {'âœ… è‰¯å¥½' if time_variance < 1000 else 'âš ï¸ éœ€å…³æ³¨'}")
        
        # çº¿ç¨‹çœŸå®æ€§éªŒè¯
        thread_names = [result.thread_name for result in results.values()]
        unique_thread_names = set(thread_names)
        logger.info(f"\nğŸ§µ çº¿ç¨‹çœŸå®æ€§éªŒè¯:")
        logger.info(f"   - çº¿ç¨‹åç§°æ•°é‡: {len(unique_thread_names)}")
        logger.info(f"   - çœŸå®å¤šçº¿ç¨‹: {'âœ… æ˜¯' if len(unique_thread_names) == len(results) else 'âŒ å¦'}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§µ Cascade çœŸæ­£çš„å¤šçº¿ç¨‹å¤šå®ä¾‹æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
    test_files = [
        "æˆ‘ç°åœ¨å¼€å§‹å½•éŸ³ï¼Œç†è®ºä¸Šä¼šæœ‰ä¸¤ä¸ªæ–‡ä»¶.wav"
    ]
    
    # å¯»æ‰¾å¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶
    audio_file = None
    for file_path in test_files:
        if os.path.exists(file_path):
            audio_file = file_path
            break
    
    if not audio_file:
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘æ–‡ä»¶")
        print("è¯·å°†éŸ³é¢‘æ–‡ä»¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼Œæ”¯æŒçš„æ–‡ä»¶å:")
        for file_path in test_files:
            print(f"  - {file_path}")
        return
    
    # æµ‹è¯•é…ç½®
    num_threads = 18  # ä½¿ç”¨4ä¸ªçº¿ç¨‹æµ‹è¯•
    chunk_size = 4096  # 4KBå—å¤§å°
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = RealMultithreadTestSuite(
        audio_file=audio_file,
        num_threads=num_threads,
        chunk_size=chunk_size
    )
    
    try:
        # è¿è¡ŒçœŸæ­£çš„å¤šçº¿ç¨‹æµ‹è¯•
        start_time = time.time()
        results = test_suite.run_real_multithread_test()
        end_time = time.time()
        
        # åˆ†æç»“æœ
        test_suite.analyze_results(results)
        
        # æ€»ä½“æµ‹è¯•ç»“æœ
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {(end_time - start_time):.2f} ç§’")
        print(f"âœ… æˆåŠŸçº¿ç¨‹: {len(results)} / {num_threads}")
        
        if len(results) == num_threads:
            print("ğŸ† æ‰€æœ‰çº¿ç¨‹å‡æˆåŠŸå®Œæˆï¼ŒçœŸæ­£çš„å¤šçº¿ç¨‹å¤šå®ä¾‹æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("âš ï¸  éƒ¨åˆ†çº¿ç¨‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        logger.exception("æµ‹è¯•å¼‚å¸¸è¯¦æƒ…:")


if __name__ == "__main__":
    # æ³¨æ„ï¼šè¿™é‡Œä¸ä½¿ç”¨asyncio.runï¼Œå› ä¸ºä¸»è¦é€»è¾‘åœ¨åŒæ­¥çš„å¤šçº¿ç¨‹ä¸­
    import asyncio
    asyncio.run(main())
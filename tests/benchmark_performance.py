#!/usr/bin/env python3
"""
Cascade 1:1:1æž¶æž„æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•é‡æž„åŽçš„æ€§èƒ½è¡¨çŽ°ï¼ŒåŒ…æ‹¬ï¼š
- å¤„ç†å»¶è¿Ÿ
- åžåé‡
- å†…å­˜ä½¿ç”¨
- CPUä½¿ç”¨çŽ‡
"""

import asyncio
import os
import sys
import time
from dataclasses import dataclass

import numpy as np
import psutil

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import cascade
from cascade.stream.processor import StreamProcessor


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æžœ"""
    test_name: str
    duration_seconds: float
    total_frames: int
    frames_per_second: float
    avg_latency_ms: float
    max_latency_ms: float
    min_latency_ms: float
    memory_usage_mb: float
    cpu_usage_percent: float
    success_rate: float


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""

    def __init__(self):
        self.results: list[BenchmarkResult] = []
        self.process = psutil.Process()

    def generate_test_audio(self, duration_seconds: float, sample_rate: int = 16000) -> bytes:
        """ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ•°æ®"""
        samples = int(duration_seconds * sample_rate)
        t = np.linspace(0, duration_seconds, samples, False)

        # ç”Ÿæˆæ··åˆé¢‘çŽ‡çš„éŸ³é¢‘ä¿¡å·
        audio_data = (
            0.3 * np.sin(2 * np.pi * 440 * t) +  # 440Hz
            0.2 * np.sin(2 * np.pi * 880 * t) +  # 880Hz
            0.1 * np.random.normal(0, 0.1, samples)  # å™ªå£°
        )

        # è½¬æ¢ä¸ºint16æ ¼å¼
        audio_bytes = (audio_data * 32767).astype(np.int16).tobytes()
        return audio_bytes

    def measure_system_resources(self) -> dict[str, float]:
        """æµ‹é‡ç³»ç»Ÿèµ„æºä½¿ç”¨"""
        memory_info = self.process.memory_info()
        cpu_percent = self.process.cpu_percent()

        return {
            'memory_mb': memory_info.rss / 1024 / 1024,
            'cpu_percent': cpu_percent
        }

    async def benchmark_single_instance(self, duration: float = 5.0) -> BenchmarkResult:
        """æµ‹è¯•å•å®žä¾‹å¤„ç†æ€§èƒ½"""
        print(f"ðŸ”„ å¼€å§‹å•å®žä¾‹æ€§èƒ½æµ‹è¯• ({duration}ç§’éŸ³é¢‘)")

        # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
        audio_data = self.generate_test_audio(duration)

        # æµ‹é‡å¼€å§‹æ—¶çš„èµ„æº
        start_resources = self.measure_system_resources()

        # å¼€å§‹æµ‹è¯•
        start_time = time.time()
        latencies = []
        total_frames = 0
        success_count = 0

        try:
            async for result in cascade.process_audio_file(audio_data):
                frame_time = time.time()
                latency_ms = (frame_time - start_time) * 1000
                latencies.append(latency_ms)
                total_frames += 1
                success_count += 1

                # é™åˆ¶æµ‹è¯•æ—¶é—´
                if time.time() - start_time > duration + 2:
                    break

        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

        end_time = time.time()
        test_duration = end_time - start_time

        # æµ‹é‡ç»“æŸæ—¶çš„èµ„æº
        end_resources = self.measure_system_resources()

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        fps = total_frames / test_duration if test_duration > 0 else 0
        avg_latency = np.mean(latencies) if latencies else 0
        max_latency = np.max(latencies) if latencies else 0
        min_latency = np.min(latencies) if latencies else 0
        success_rate = success_count / total_frames if total_frames > 0 else 0

        result = BenchmarkResult(
            test_name="å•å®žä¾‹å¤„ç†",
            duration_seconds=test_duration,
            total_frames=total_frames,
            frames_per_second=fps,
            avg_latency_ms=float(avg_latency),
            max_latency_ms=float(max_latency),
            min_latency_ms=float(min_latency),
            memory_usage_mb=end_resources['memory_mb'],
            cpu_usage_percent=end_resources['cpu_percent'],
            success_rate=success_rate
        )

        self.results.append(result)
        print(f"âœ… å•å®žä¾‹æµ‹è¯•å®Œæˆ: {total_frames}å¸§, {fps:.1f}fps")
        return result

    async def benchmark_stream_processor(self, duration: float = 5.0) -> BenchmarkResult:
        """æµ‹è¯•StreamProcessoræ€§èƒ½"""
        print(f"ðŸ”„ å¼€å§‹StreamProcessoræ€§èƒ½æµ‹è¯• ({duration}ç§’éŸ³é¢‘)")

        # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
        audio_data = self.generate_test_audio(duration)

        # åˆ›å»ºé…ç½®å’Œå¤„ç†å™¨
        config = cascade.create_default_config()
        processor = StreamProcessor(config)

        # æµ‹é‡å¼€å§‹æ—¶çš„èµ„æº
        start_resources = self.measure_system_resources()

        await processor.start()

        # å¼€å§‹æµ‹è¯•
        start_time = time.time()
        latencies = []
        total_frames = 0
        success_count = 0

        try:
            # åˆ†å—å¤„ç†
            chunk_size = 1024  # 1KB chunks
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]

                chunk_start = time.time()
                results = await processor.process_chunk(chunk)
                chunk_end = time.time()

                latency_ms = (chunk_end - chunk_start) * 1000
                latencies.append(latency_ms)
                total_frames += len(results)
                success_count += len(results)

                # é™åˆ¶æµ‹è¯•æ—¶é—´
                if time.time() - start_time > duration + 2:
                    break

        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

        finally:
            await processor.stop()

        end_time = time.time()
        test_duration = end_time - start_time

        # æµ‹é‡ç»“æŸæ—¶çš„èµ„æº
        end_resources = self.measure_system_resources()

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        fps = total_frames / test_duration if test_duration > 0 else 0
        avg_latency = np.mean(latencies) if latencies else 0
        max_latency = np.max(latencies) if latencies else 0
        min_latency = np.min(latencies) if latencies else 0
        success_rate = success_count / max(total_frames, 1)

        result = BenchmarkResult(
            test_name="StreamProcessor",
            duration_seconds=test_duration,
            total_frames=total_frames,
            frames_per_second=fps,
            avg_latency_ms=float(avg_latency),
            max_latency_ms=float(max_latency),
            min_latency_ms=float(min_latency),
            memory_usage_mb=end_resources['memory_mb'],
            cpu_usage_percent=end_resources['cpu_percent'],
            success_rate=success_rate
        )

        self.results.append(result)
        print(f"âœ… StreamProcessoræµ‹è¯•å®Œæˆ: {total_frames}å¸§, {fps:.1f}fps")
        return result

    async def benchmark_concurrent_processing(self, num_concurrent: int = 3) -> BenchmarkResult:
        """æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½"""
        print(f"ðŸ”„ å¼€å§‹å¹¶å‘å¤„ç†æ€§èƒ½æµ‹è¯• ({num_concurrent}ä¸ªå¹¶å‘ä»»åŠ¡)")

        # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
        audio_data = self.generate_test_audio(3.0)  # 3ç§’éŸ³é¢‘

        # æµ‹é‡å¼€å§‹æ—¶çš„èµ„æº
        start_resources = self.measure_system_resources()

        # å¼€å§‹æµ‹è¯•
        start_time = time.time()

        async def process_task(task_id: int):
            """å•ä¸ªå¤„ç†ä»»åŠ¡"""
            results = []
            try:
                async for result in cascade.process_audio_file(audio_data):
                    results.append(result)
                return len(results)
            except Exception as e:
                print(f"âŒ ä»»åŠ¡{task_id}å‡ºé”™: {e}")
                return 0

        # å¹¶å‘æ‰§è¡Œä»»åŠ¡
        tasks = [process_task(i) for i in range(num_concurrent)]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        end_time = time.time()
        test_duration = end_time - start_time

        # æµ‹é‡ç»“æŸæ—¶çš„èµ„æº
        end_resources = self.measure_system_resources()

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_frames = sum(r for r in results if isinstance(r, int))
        success_count = sum(1 for r in results if isinstance(r, int) and r > 0)
        fps = total_frames / test_duration if test_duration > 0 else 0
        success_rate = success_count / num_concurrent

        result = BenchmarkResult(
            test_name=f"å¹¶å‘å¤„ç†({num_concurrent}ä»»åŠ¡)",
            duration_seconds=test_duration,
            total_frames=total_frames,
            frames_per_second=fps,
            avg_latency_ms=test_duration * 1000 / num_concurrent,
            max_latency_ms=test_duration * 1000,
            min_latency_ms=test_duration * 1000 / num_concurrent,
            memory_usage_mb=end_resources['memory_mb'],
            cpu_usage_percent=end_resources['cpu_percent'],
            success_rate=success_rate
        )

        self.results.append(result)
        print(f"âœ… å¹¶å‘æµ‹è¯•å®Œæˆ: {total_frames}å¸§, {success_count}/{num_concurrent}ä»»åŠ¡æˆåŠŸ")
        return result

    def print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æžœ"""
        print("\n" + "="*80)
        print("ðŸ† Cascade 1:1:1æž¶æž„æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æžœ")
        print("="*80)

        for result in self.results:
            print(f"\nðŸ“Š {result.test_name}")
            print(f"   â±ï¸  æµ‹è¯•æ—¶é•¿: {result.duration_seconds:.2f}ç§’")
            print(f"   ðŸŽ¯ å¤„ç†å¸§æ•°: {result.total_frames}")
            print(f"   âš¡ å¤„ç†é€Ÿåº¦: {result.frames_per_second:.1f} fps")
            print(f"   ðŸ“ˆ å¹³å‡å»¶è¿Ÿ: {result.avg_latency_ms:.2f}ms")
            print(f"   ðŸ“Š å»¶è¿ŸèŒƒå›´: {result.min_latency_ms:.2f}ms - {result.max_latency_ms:.2f}ms")
            print(f"   ðŸ’¾ å†…å­˜ä½¿ç”¨: {result.memory_usage_mb:.1f}MB")
            print(f"   ðŸ–¥ï¸  CPUä½¿ç”¨: {result.cpu_usage_percent:.1f}%")
            print(f"   âœ… æˆåŠŸçŽ‡: {result.success_rate*100:.1f}%")

        print("\n" + "="*80)
        print("ðŸŽ¯ æ€§èƒ½æ€»ç»“")
        print("="*80)

        if self.results:
            avg_fps = np.mean([r.frames_per_second for r in self.results])
            avg_latency = np.mean([r.avg_latency_ms for r in self.results])
            avg_memory = np.mean([r.memory_usage_mb for r in self.results])
            avg_success = np.mean([r.success_rate for r in self.results])

            print(f"å¹³å‡å¤„ç†é€Ÿåº¦: {avg_fps:.1f} fps")
            print(f"å¹³å‡å¤„ç†å»¶è¿Ÿ: {avg_latency:.2f} ms")
            print(f"å¹³å‡å†…å­˜ä½¿ç”¨: {avg_memory:.1f} MB")
            print(f"å¹³å‡æˆåŠŸçŽ‡: {avg_success*100:.1f}%")

            # æ€§èƒ½è¯„çº§
            if avg_fps > 100 and avg_latency < 50:
                grade = "ðŸ† ä¼˜ç§€"
            elif avg_fps > 50 and avg_latency < 100:
                grade = "ðŸ¥ˆ è‰¯å¥½"
            elif avg_fps > 20 and avg_latency < 200:
                grade = "ðŸ¥‰ ä¸€èˆ¬"
            else:
                grade = "âš ï¸  éœ€è¦ä¼˜åŒ–"

            print(f"æ€§èƒ½è¯„çº§: {grade}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ðŸš€ Cascade 1:1:1æž¶æž„æ€§èƒ½åŸºå‡†æµ‹è¯•å¼€å§‹")
    print("="*80)

    benchmark = PerformanceBenchmark()

    try:
        # 1. å•å®žä¾‹å¤„ç†æµ‹è¯•
        await benchmark.benchmark_single_instance(duration=3.0)

        # 2. StreamProcessoræµ‹è¯•
        await benchmark.benchmark_stream_processor(duration=3.0)

        # 3. å¹¶å‘å¤„ç†æµ‹è¯•
        await benchmark.benchmark_concurrent_processing(num_concurrent=2)

        # æ‰“å°ç»“æžœ
        benchmark.print_results()

    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())

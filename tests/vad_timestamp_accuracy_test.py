#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•è„šæœ¬

ä¸“æ³¨äºéªŒè¯Cascade VADç³»ç»Ÿçš„æ—¶é—´æˆ³å‡†ç¡®æ€§å’Œè¯­éŸ³å—æ‹¼æ¥æ•ˆæœã€‚
ä½¿ç”¨Ground Truthæ•°æ®: 0.768330ç§’ - 5.009294ç§’

åŠŸèƒ½ï¼š
1. åŠ è½½éŸ³é¢‘æ–‡ä»¶å’ŒGround Truthæ ‡æ³¨
2. è¿è¡ŒVADæ£€æµ‹å¹¶æ”¶é›†ç»“æœ
3. åˆ†ææ—¶é—´æˆ³å‡†ç¡®æ€§
4. ç”Ÿæˆå¯è§†åŒ–æµ‹è¯•æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python tests/vad_timestamp_accuracy_test.py
"""

import asyncio
import logging
import sys
import time
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional

import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
from pydantic import BaseModel

# Cascadeå¯¼å…¥
from cascade.types import VADConfig, AudioConfig, AudioChunk, VADResult
from cascade.backends import create_vad_backend

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TestConfig(BaseModel):
    """æµ‹è¯•é…ç½®"""
    audio_file: str = "è¯·é—®ç”µåŠ¨æ±½è½¦å’Œä¼ ç»Ÿæ±½è½¦æ¯”èµ·æ¥å“ªä¸ªæ›´å¥½å•Šï¼Ÿ.wav"
    ground_truth_file: str = "ground_truth.txt"
    output_report: str = "vad_timestamp_accuracy_report.png"
    
    # VADé…ç½®
    vad_threshold: float = 0.5
    chunk_duration_ms: int = 512
    overlap_ms: int = 50
    
    # å‡†ç¡®æ€§é˜ˆå€¼
    acceptable_error_ms: float = 100.0  # å¯æ¥å—çš„æ—¶é—´æˆ³è¯¯å·®


class GroundTruthSegment(BaseModel):
    """Ground Truthè¯­éŸ³æ®µ"""
    start_sec: float
    end_sec: float
    duration_sec: float
    
    @classmethod
    def from_audacity_line(cls, line: str) -> Optional['GroundTruthSegment']:
        """ä»Audacityå¯¼å‡ºçš„æ ‡ç­¾è¡Œåˆ›å»ºå®ä¾‹"""
        parts = line.strip().split('\t')
        if len(parts) >= 2:
            try:
                start = float(parts[0])
                end = float(parts[1])
                return cls(
                    start_sec=start,
                    end_sec=end,
                    duration_sec=end - start
                )
            except ValueError:
                return None
        return None


class VADDetectionResult(BaseModel):
    """VADæ£€æµ‹ç»“æœ"""
    start_sec: float
    end_sec: float
    duration_sec: float
    confidence: float
    chunk_count: int


class AccuracyMetrics(BaseModel):
    """å‡†ç¡®æ€§æŒ‡æ ‡"""
    start_error_ms: float
    end_error_ms: float
    average_error_ms: float
    duration_error_sec: float
    is_detected: bool
    detection_count: int
    
    # è¯„ä¼°ç»“æœ
    start_accuracy: str  # "ä¼˜ç§€"/"è‰¯å¥½"/"å¯æ¥å—"/"ä¸åˆæ ¼"
    end_accuracy: str
    overall_accuracy: str


class VADTimestampAccuracyTest:
    """VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•å™¨"""
    
    def __init__(self, config: TestConfig):
        self.config = config
        self.ground_truth: Optional[GroundTruthSegment] = None
        self.vad_results: List[VADResult] = []
        self.detected_segments: List[VADDetectionResult] = []
        self.metrics: Optional[AccuracyMetrics] = None
        
    def load_ground_truth(self) -> bool:
        """åŠ è½½Ground Truthæ•°æ®"""
        try:
            gt_path = Path(self.config.ground_truth_file)
            if not gt_path.exists():
                logger.error(f"Ground Truthæ–‡ä»¶ä¸å­˜åœ¨: {gt_path}")
                return False
                
            with open(gt_path, 'r', encoding='utf-8') as f:
                for line in f:
                    segment = GroundTruthSegment.from_audacity_line(line)
                    if segment:
                        self.ground_truth = segment
                        logger.info(f"åŠ è½½Ground Truth: {segment.start_sec:.3f}s - {segment.end_sec:.3f}s")
                        return True
                        
            logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„Ground Truthæ•°æ®")
            return False
            
        except Exception as e:
            logger.error(f"åŠ è½½Ground Truthå¤±è´¥: {e}")
            return False
    
    def load_audio(self) -> Optional[np.ndarray]:
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        try:
            audio_path = Path(self.config.audio_file)
            if not audio_path.exists():
                logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                return None
                
            # ä½¿ç”¨soundfileåŠ è½½éŸ³é¢‘
            audio_data, sample_rate = sf.read(str(audio_path), dtype='float32')
            
            logger.info(f"éŸ³é¢‘åŠ è½½æˆåŠŸ: {len(audio_data)/sample_rate:.2f}ç§’, {sample_rate}Hz")
            
            # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬æ¢ä¸ºå•å£°é“
            if audio_data.ndim > 1:
                audio_data = np.mean(audio_data, axis=1)
                
            # é‡é‡‡æ ·åˆ°16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
            if sample_rate != 16000:
                from scipy import signal
                audio_data = signal.resample(
                    audio_data, 
                    int(len(audio_data) * 16000 / sample_rate)
                )
                logger.info(f"éŸ³é¢‘é‡é‡‡æ ·: {sample_rate}Hz -> 16000Hz")
                
            return audio_data.astype(np.float32)
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
            return None
    
    async def run_vad_detection(self, audio_data: np.ndarray) -> bool:
        """è¿è¡ŒVADæ£€æµ‹"""
        try:
            # é…ç½®VAD (å¯ç”¨100mså»¶è¿Ÿè¡¥å¿)
            vad_config = VADConfig(
                backend="silero",
                threshold=self.config.vad_threshold,
                chunk_duration_ms=self.config.chunk_duration_ms,
                overlap_ms=self.config.overlap_ms,
                min_speech_duration_ms=100,
                workers=1,
                compensation_ms=250  # å¯ç”¨100mså»¶è¿Ÿè¡¥å¿
            )
            
            audio_config = AudioConfig(
                sample_rate=16000,
                channels=1,
                format="wav",
                dtype="float32"
            )
            
            logger.info("åˆå§‹åŒ–Silero VADåç«¯...")
            backend = create_vad_backend(vad_config)
            await backend.initialize()
            
            # åˆ†å—å¤„ç†éŸ³é¢‘
            chunk_size = int(self.config.chunk_duration_ms * 16000 / 1000)  # 512ms @ 16kHz
            overlap_size = int(self.config.overlap_ms * 16000 / 1000)      # 50ms @ 16kHz
            step_size = chunk_size - overlap_size
            
            logger.info(f"å¼€å§‹VADæ£€æµ‹: å—å¤§å°={chunk_size}, é‡å ={overlap_size}, æ­¥é•¿={step_size}")
            
            self.vad_results = []
            for i in range(0, len(audio_data), step_size):
                # æå–éŸ³é¢‘å—
                chunk_data = audio_data[i:i+chunk_size]
                if len(chunk_data) < chunk_size:
                    # æœ€åä¸€å—è¡¥é›¶
                    padded = np.zeros(chunk_size, dtype=np.float32)
                    padded[:len(chunk_data)] = chunk_data
                    chunk_data = padded
                
                # åˆ›å»ºAudioChunk
                timestamp_ms = i / 16000 * 1000
                chunk = AudioChunk(
                    data=chunk_data,
                    sequence_number=len(self.vad_results),
                    start_frame=i,
                    chunk_size=chunk_size,
                    timestamp_ms=timestamp_ms,
                    sample_rate=16000
                )
                
                # VADæ£€æµ‹
                result = backend.process_chunk(chunk)
                self.vad_results.append(result)
                
                # å®æ—¶æ—¥å¿—
                time_str = f"{result.start_ms/1000:.2f}-{result.end_ms/1000:.2f}s"
                status = "ğŸ—£ï¸è¯­éŸ³" if result.is_speech else "ğŸ”‡é™éŸ³"
                logger.debug(f"{status} | {time_str} | æ¦‚ç‡: {result.probability:.3f}")
            
            await backend.close()
            logger.info(f"VADæ£€æµ‹å®Œæˆ: {len(self.vad_results)}ä¸ªå—")
            return True
            
        except Exception as e:
            logger.error(f"VADæ£€æµ‹å¤±è´¥: {e}")
            return False
    
    def merge_speech_segments(self) -> None:
        """åˆå¹¶è¿ç»­çš„è¯­éŸ³å—ä¸ºè¯­éŸ³æ®µ"""
        if not self.vad_results:
            return
            
        current_segment = None
        speech_chunks = []
        
        for result in self.vad_results:
            if result.is_speech:
                if current_segment is None:
                    # å¼€å§‹æ–°è¯­éŸ³æ®µ
                    current_segment = {
                        'start_ms': result.start_ms,
                        'end_ms': result.end_ms,
                        'confidences': [result.confidence],
                        'chunk_count': 1
                    }
                else:
                    # æ‰©å±•å½“å‰è¯­éŸ³æ®µ
                    current_segment['end_ms'] = result.end_ms
                    current_segment['confidences'].append(result.confidence)
                    current_segment['chunk_count'] += 1
            else:
                if current_segment is not None:
                    # è¯­éŸ³æ®µç»“æŸ
                    speech_chunks.append(current_segment)
                    current_segment = None
        
        # å¤„ç†æœ€åä¸€ä¸ªè¯­éŸ³æ®µ
        if current_segment is not None:
            speech_chunks.append(current_segment)
        
        # è½¬æ¢ä¸ºVADDetectionResult
        self.detected_segments = []
        for segment in speech_chunks:
            self.detected_segments.append(VADDetectionResult(
                start_sec=segment['start_ms'] / 1000.0,
                end_sec=segment['end_ms'] / 1000.0,
                duration_sec=(segment['end_ms'] - segment['start_ms']) / 1000.0,
                confidence=np.mean(segment['confidences']),
                chunk_count=segment['chunk_count']
            ))
        
        logger.info(f"æ£€æµ‹åˆ° {len(self.detected_segments)} ä¸ªè¯­éŸ³æ®µ")
        for i, segment in enumerate(self.detected_segments):
            logger.info(f"  è¯­éŸ³æ®µ{i+1}: {segment.start_sec:.3f}s-{segment.end_sec:.3f}s "
                       f"(æ—¶é•¿: {segment.duration_sec:.3f}s, ç½®ä¿¡åº¦: {segment.confidence:.3f})")
    
    def calculate_accuracy_metrics(self) -> None:
        """è®¡ç®—å‡†ç¡®æ€§æŒ‡æ ‡"""
        if not self.ground_truth:
            logger.error("ç¼ºå°‘Ground Truthæ•°æ®")
            return
            
        # é»˜è®¤æŒ‡æ ‡ï¼ˆæœªæ£€æµ‹åˆ°è¯­éŸ³ï¼‰
        start_error = float('inf')
        end_error = float('inf')
        is_detected = len(self.detected_segments) > 0
        
        if is_detected and len(self.detected_segments) > 0:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„è¯­éŸ³æ®µï¼ˆç†æƒ³æƒ…å†µä¸‹åº”è¯¥åªæœ‰ä¸€ä¸ªï¼‰
            primary_segment = self.detected_segments[0]
            
            # å¦‚æœæœ‰å¤šä¸ªè¯­éŸ³æ®µï¼Œåˆå¹¶ä¸ºä¸€ä¸ªè¿ç»­æ®µ
            if len(self.detected_segments) > 1:
                start_sec = min(s.start_sec for s in self.detected_segments)
                end_sec = max(s.end_sec for s in self.detected_segments)
                primary_segment = VADDetectionResult(
                    start_sec=start_sec,
                    end_sec=end_sec,
                    duration_sec=end_sec - start_sec,
                    confidence=np.mean([s.confidence for s in self.detected_segments]),
                    chunk_count=sum(s.chunk_count for s in self.detected_segments)
                )
            
            # è®¡ç®—æ—¶é—´æˆ³è¯¯å·®
            start_error = abs(primary_segment.start_sec - self.ground_truth.start_sec) * 1000  # ms
            end_error = abs(primary_segment.end_sec - self.ground_truth.end_sec) * 1000        # ms
        
        average_error = (start_error + end_error) / 2 if start_error != float('inf') else float('inf')
        
        # è®¡ç®—æ—¶é•¿è¯¯å·®
        if is_detected and len(self.detected_segments) > 0:
            detected_duration = sum(s.duration_sec for s in self.detected_segments)
            duration_error = abs(detected_duration - self.ground_truth.duration_sec)
        else:
            duration_error = self.ground_truth.duration_sec
        
        # è¯„ä¼°å‡†ç¡®æ€§ç­‰çº§
        def evaluate_accuracy(error_ms: float) -> str:
            if error_ms == float('inf'):
                return "ä¸åˆæ ¼"
            elif error_ms <= 50:
                return "ä¼˜ç§€"
            elif error_ms <= 100:
                return "è‰¯å¥½"
            elif error_ms <= 200:
                return "å¯æ¥å—"
            else:
                return "ä¸åˆæ ¼"
        
        self.metrics = AccuracyMetrics(
            start_error_ms=start_error,
            end_error_ms=end_error,
            average_error_ms=average_error,
            duration_error_sec=duration_error,
            is_detected=is_detected,
            detection_count=len(self.detected_segments),
            start_accuracy=evaluate_accuracy(start_error),
            end_accuracy=evaluate_accuracy(end_error),
            overall_accuracy=evaluate_accuracy(average_error)
        )
    
    def generate_visualization(self, audio_data: np.ndarray) -> None:
        """ç”Ÿæˆå¯è§†åŒ–æµ‹è¯•æŠ¥å‘Š"""
        if not self.ground_truth or not self.metrics:
            logger.error("ç¼ºå°‘å¿…è¦æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š")
            return
        
        try:
            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False
            
            # åˆ›å»ºå›¾å½¢
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))
            
            # æ—¶é—´è½´
            time_axis = np.arange(len(audio_data)) / 16000
            
            # === ç¬¬ä¸€ä¸ªå­å›¾ï¼šéŸ³é¢‘æ³¢å½¢å’Œæ—¶é—´æˆ³å¯¹æ¯” ===
            ax1.plot(time_axis, audio_data, color='gray', alpha=0.7, linewidth=0.5, label='éŸ³é¢‘æ³¢å½¢')
            
            # Ground TruthåŒºåŸŸï¼ˆç»¿è‰²ï¼‰
            ax1.axvspan(self.ground_truth.start_sec, self.ground_truth.end_sec, 
                       color='green', alpha=0.3, label='Ground Truth')
            
            # VADæ£€æµ‹åŒºåŸŸï¼ˆçº¢è‰²ï¼‰
            for segment in self.detected_segments:
                ax1.axvspan(segment.start_sec, segment.end_sec, 
                           color='red', alpha=0.4, label='VADæ£€æµ‹' if segment == self.detected_segments[0] else "")
            
            # æ ‡æ³¨æ—¶é—´æˆ³
            ax1.axvline(self.ground_truth.start_sec, color='green', linestyle='--', alpha=0.8)
            ax1.axvline(self.ground_truth.end_sec, color='green', linestyle='--', alpha=0.8)
            
            if self.detected_segments:
                primary = self.detected_segments[0]
                ax1.axvline(primary.start_sec, color='red', linestyle='--', alpha=0.8)
                ax1.axvline(primary.end_sec, color='red', linestyle='--', alpha=0.8)
            
            ax1.set_title('VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•æŠ¥å‘Š', fontsize=16, fontweight='bold')
            ax1.set_xlabel('æ—¶é—´ (ç§’)', fontsize=12)
            ax1.set_ylabel('æŒ¯å¹…', fontsize=12)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # === ç¬¬äºŒä¸ªå­å›¾ï¼šVADæ¦‚ç‡æ›²çº¿ ===
            if self.vad_results:
                times = [r.start_ms/1000 for r in self.vad_results]
                probs = [r.probability for r in self.vad_results]
                
                ax2.plot(times, probs, 'r-', linewidth=2, label='VADæ¦‚ç‡')
                ax2.axhline(y=self.config.vad_threshold, color='blue', linestyle='--', 
                           alpha=0.7, label=f'é˜ˆå€¼ ({self.config.vad_threshold})')
                
                # æ ‡æ³¨è¯­éŸ³åŒºåŸŸ
                for result in self.vad_results:
                    if result.is_speech:
                        ax2.axvspan(result.start_ms/1000, result.end_ms/1000, 
                                   color='yellow', alpha=0.2)
                
                ax2.set_xlabel('æ—¶é—´ (ç§’)', fontsize=12)
                ax2.set_ylabel('VADæ¦‚ç‡', fontsize=12)
                ax2.set_ylim(0, 1)
                ax2.legend()
                ax2.grid(True, alpha=0.3)
            
            # === æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ ===
            stats_text = self._generate_stats_text()
            fig.text(0.02, 0.02, stats_text, fontsize=10, verticalalignment='bottom',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="wheat", alpha=0.8))
            
            plt.tight_layout(rect=[0, 0.25, 1, 1])
            plt.savefig(self.config.output_report, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"å¯è§†åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {self.config.output_report}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šå¤±è´¥: {e}")
    
    def _generate_stats_text(self) -> str:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬"""
        if not self.metrics or not self.ground_truth:
            return ""
        
        stats = [
            "=== VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•ç»“æœ ===",
            f"Ground Truth: {self.ground_truth.start_sec:.3f}s - {self.ground_truth.end_sec:.3f}s",
            f"æ£€æµ‹ç»“æœ: {len(self.detected_segments)}ä¸ªè¯­éŸ³æ®µ",
            "",
            "=== æ—¶é—´æˆ³è¯¯å·®åˆ†æ ===",
            f"å¼€å§‹æ—¶é—´è¯¯å·®: {self.metrics.start_error_ms:.1f}ms ({self.metrics.start_accuracy})",
            f"ç»“æŸæ—¶é—´è¯¯å·®: {self.metrics.end_error_ms:.1f}ms ({self.metrics.end_accuracy})",
            f"å¹³å‡æ—¶é—´æˆ³è¯¯å·®: {self.metrics.average_error_ms:.1f}ms ({self.metrics.overall_accuracy})",
            f"æ—¶é•¿è¯¯å·®: {self.metrics.duration_error_sec:.3f}s",
            "",
            "=== æ£€æµ‹çŠ¶æ€ ===",
            f"æ˜¯å¦æ£€æµ‹åˆ°è¯­éŸ³: {'æ˜¯' if self.metrics.is_detected else 'å¦'}",
            f"è¯­éŸ³æ®µæ•°é‡: {self.metrics.detection_count}",
            f"VADé…ç½®: é˜ˆå€¼={self.config.vad_threshold}, å—å¤§å°={self.config.chunk_duration_ms}ms",
        ]
        
        if self.detected_segments:
            stats.extend([
                "",
                "=== æ£€æµ‹åˆ°çš„è¯­éŸ³æ®µ ===",
            ])
            for i, segment in enumerate(self.detected_segments):
                stats.append(f"æ®µ{i+1}: {segment.start_sec:.3f}s-{segment.end_sec:.3f}s "
                           f"(æ—¶é•¿:{segment.duration_sec:.3f}s, ç½®ä¿¡åº¦:{segment.confidence:.3f})")
        
        return "\n".join(stats)
    
    async def run_test(self) -> bool:
        """æ‰§è¡Œå®Œæ•´æµ‹è¯•æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•")
        
        # 1. åŠ è½½Ground Truth
        if not self.load_ground_truth():
            return False
        
        # 2. åŠ è½½éŸ³é¢‘
        audio_data = self.load_audio()
        if audio_data is None:
            return False
        
        # 3. VADæ£€æµ‹
        if not await self.run_vad_detection(audio_data):
            return False
        
        # 4. åˆå¹¶è¯­éŸ³æ®µ
        self.merge_speech_segments()
        
        # 5. è®¡ç®—å‡†ç¡®æ€§æŒ‡æ ‡
        self.calculate_accuracy_metrics()
        
        # 6. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
        self.generate_visualization(audio_data)
        
        # 7. è¾“å‡ºç»“æœ
        self._print_test_results()
        
        logger.info("âœ… VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•å®Œæˆ")
        return True
    
    def _print_test_results(self) -> None:
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        if not self.metrics:
            return
        
        print("\n" + "="*60)
        print("ğŸ¯ VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•ç»“æœ")
        print("="*60)
        
        print(f"ğŸ“Š æ€»ä½“è¯„ä¼°: {self.metrics.overall_accuracy}")
        print(f"ğŸ“ å¹³å‡æ—¶é—´æˆ³è¯¯å·®: {self.metrics.average_error_ms:.1f}ms")
        print(f"ğŸ¤ æ£€æµ‹è¯­éŸ³æ®µæ•°: {self.metrics.detection_count}")
        
        if self.metrics.is_detected:
            print(f"âœ… æ£€æµ‹çŠ¶æ€: æˆåŠŸæ£€æµ‹åˆ°è¯­éŸ³")
            print(f"â±ï¸  å¼€å§‹æ—¶é—´è¯¯å·®: {self.metrics.start_error_ms:.1f}ms ({self.metrics.start_accuracy})")
            print(f"â±ï¸  ç»“æŸæ—¶é—´è¯¯å·®: {self.metrics.end_error_ms:.1f}ms ({self.metrics.end_accuracy})")
        else:
            print(f"âŒ æ£€æµ‹çŠ¶æ€: æœªæ£€æµ‹åˆ°è¯­éŸ³")
        
        print(f"ğŸ“ˆ å¯è§†åŒ–æŠ¥å‘Š: {self.config.output_report}")
        print("="*60)


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ VADæ—¶é—´æˆ³å‡†ç¡®æ€§æµ‹è¯•å·¥å…·")
    print("ä¸“ç”¨äºéªŒè¯Cascade VADç³»ç»Ÿçš„æ—¶é—´æˆ³å‡†ç¡®æ€§")
    print("-" * 50)
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = TestConfig()
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not Path(config.audio_file).exists():
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {config.audio_file}")
        print("è¯·å°†æµ‹è¯•éŸ³é¢‘æ–‡ä»¶æ”¾åœ¨å½“å‰ç›®å½•ä¸‹")
        return
    
    if not Path(config.ground_truth_file).exists():
        print(f"âŒ Ground Truthæ–‡ä»¶ä¸å­˜åœ¨: {config.ground_truth_file}")
        print("è¯·å‚è€ƒdocs/how_to_label_ground_truth.mdåˆ›å»ºæ ‡æ³¨æ–‡ä»¶")
        return
    
    # è¿è¡Œæµ‹è¯•
    test = VADTimestampAccuracyTest(config)
    success = await test.run_test()
    
    if success:
        print("\nğŸ‰ æµ‹è¯•æ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“Š æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: {config.output_report}")
    else:
        print("\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
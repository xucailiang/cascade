# Cascade 性能测试报告

## 1. 测试概述

本报告记录了对Cascade流式音频处理库的性能测试结果。测试重点关注流式音频处理接口和高并发调用场景下的性能表现，并对性能瓶颈进行了分析。

**测试环境**:
- **CPU**: AMD Ryzen 7 9700X (8 物理核心, 16 逻辑核心)
- **操作系统**: Fedora Linux
- **Python版本**: 3.12
- **测试音频**: `/home/justin/workspace/cascade/新能源汽车和燃油车相比有哪些优缺点？.wav`

## 2. 测试结果与分析

### 2.1 不同音频块大小的性能

此测试旨在探究在使用`StreamProcessor.process_chunk`时，传入的音频块大小对处理延迟和吞吐量的影响。

**测试结果**:
| Chunk Size (B) | Avg Latency (ms) | Throughput (fps) |
| :--- | :--- | :--- |
| 512 | 0.12 | 1289.25 |
| 1024 | 0.18 | 1694.01 |
| 2048 | 0.37 | 1692.25 |
| 4096 | 0.74 | 1690.85 |
| 8192 | 1.43 | 1708.94 |

**分析**:
- **延迟**: 平均延迟随着块大小的增加而线性增加，这符合预期，因为处理更大的数据块需要更多时间。
- **吞吐量**: 吞吐量（每秒处理的帧数）在块大小从512B增加到1024B时显著提升，之后在1690fps左右达到平台期。
- **结论**: 对于非实时性要求高的批量处理任务，使用**1024B到8192B**的块大小可以在可接受的延迟范围内获得最佳的吞吐量。

### 2.2 并发模型对比测试

此测试旨在评估两种不同并发模型下的系统扩展能力:
1.  **独立处理器模式**: 每个并发任务都创建一个独立的`StreamProcessor`实例。
2.  **共享处理器模式**: 所有并发任务共享同一个`StreamProcessor`实例。

**测试结果**:

**独立处理器模式**
| Concurrency | Total FPS | Mem Usage (MB) | CPU Usage (%) |
| :--- | :--- | :--- | :--- |
| 1 | 1628.67 | -0.01 | 80.00 |
| 2 | 1431.19 | 0.09 | 105.50 |
| 4 | 1625.06 | -0.19 | 99.90 |
| 8 | 1634.73 | 0.09 | 100.50 |
| 12 | 1643.32 | 1.20 | 98.80 |
| 16 | 1628.40 | -0.96 | 100.10 |
| 24 | 1634.43 | -0.27 | 99.40 |
| 32 | 1634.01 | 0.02 | 99.60 |

**共享处理器模式**
| Concurrency | Total FPS | Mem Usage (MB) | CPU Usage (%) |
| :--- | :--- | :--- | :--- |
| 1 | 1672.64 | 0.27 | 106.20 |
| 2 | 2436.97 | -0.27 | 95.70 |
| 4 | 3118.65 | 0.00 | 108.40 |
| 8 | 3650.94 | 0.00 | 99.80 |
| 12 | 3893.84 | 0.00 | 96.10 |
| 16 | 3898.92 | -0.00 | 102.20 |
| 24 | 4106.80 | 0.00 | 98.50 |
| 32 | 4081.92 | 0.00 | 99.40 |

**分析**:
- **吞吐量扩展性**:
    - 在**独立模式**下，总吞吐量（Total FPS）几乎不随并发数的增加而增长，始终维持在约1630 FPS。这是因为每个独立的处理器实例都会加载自己的模型，当并发数增多时，内存占用和上下文切换开销巨大，无法带来性能提升。
    - 在**共享模式**下，总吞吐量随着并发数的增加而持续增长。在1到12个并发之间，性能提升非常显著。在12个并发之后，吞吐量增长放缓，但仍能继续提升，直到32个并发时达到约4100 FPS的峰值。
- **CPU饱和**: 在两种模式下，CPU使用率在1个并发时就已接近100%，并在更高的并发级别下保持饱和。这表明VAD处理是典型的CPU密集型任务。
- **内存使用**: **共享模式**的内存使用量非常稳定，没有随并发数的增加而显著增长，这得益于共享`StreamProcessor`实例的优化，避免了模型的重复加载。独立模式的内存增量虽然在表中不明显（因为测试时间短），但理论上会线性增长。

## 3. 性能瓶颈分析

**核心结论**: **软件层面的瓶颈在于模型实例是否共享，而硬件层面的瓶颈是CPU物理核心数。**

1.  **共享模型是关键**: 对比测试明确显示，**共享`StreamProcessor`实例**是实现高性能并发的关键。独立实例模式由于模型重复加载和资源竞争，完全无法实现性能扩展。
2.  **CPU核心数与性能拐点**: 测试环境拥有**8个物理核心**。在表现更优的共享模型下，性能的主要增长区间在1到12个并发之间，这与物理核心数高度相关。当并发任务数超过物理核心数时，性能增长依赖于操作系统的超线程技术（SMT）和任务调度，因此增速放缓。
3.  **GIL的影响**: 由于Python的全局解释器锁（GIL），即使有16个逻辑核心，单个Python进程内的多个线程也无法真正并行执行CPU密集型的Python代码。`asyncio`的并发优势在这种计算密集型场景下受到了限制。

## 4. 最终建议与最佳实践

### 4.1 部署策略

为了在生产环境中最大化利用您拥有的8核CPU，建议采用**多进程部署**策略。
-   使用 Gunicorn, uWSGI, 或 Python 的 `multiprocessing` 模块。
-   启动 **8个** worker 进程，使每个进程都能独立利用一个CPU物理核心。

### 4.2 `cascade` 库使用最佳实践

-   **单例 `StreamProcessor`**: 在每个独立的进程中，应该只维护一个`StreamProcessor`的单例。
-   **为每个音频流使用唯一`stream_id`**: 当处理多个并发音频流时（例如，来自多个WebSocket客户端），必须为每个流提供一个唯一的`stream_id`以正确隔离状态。

**示例代码**:
```python
# 在你的应用启动时
stream_processor = cascade.StreamProcessor()
await stream_processor.start()

# 当一个新的客户端连接时
async def handle_client_stream(audio_stream, client_id: str):
    # 使用 client_id 作为 stream_id
    async for result in stream_processor.process_stream(audio_stream, stream_id=client_id):
        # 处理结果
        pass
```

遵循以上实践，可以确保`cascade`在多核服务器上发挥出最佳性能，同时保证数据处理的隔离性和状态安全。
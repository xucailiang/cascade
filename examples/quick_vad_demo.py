#!/usr/bin/env python3
"""
Cascadeå¿«é€ŸVADå¤„ç†ç¤ºä¾‹
é’ˆå¯¹éŸ³é¢‘æ–‡ä»¶: "è¯·é—®ç”µåŠ¨æ±½è½¦å’Œä¼ ç»Ÿæ±½è½¦æ¯”èµ·æ¥å“ªä¸ªæ›´å¥½å•Šï¼Ÿ.wav"

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å¿«é€Ÿæ¼”ç¤ºï¼Œå±•ç¤ºCascadeçš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. 4çº¿ç¨‹å¹¶è¡ŒVADå¤„ç†
2. Silero VADæ¨¡å‹
3. å®æ—¶æ€§èƒ½ç›‘æ§
4. è¯­éŸ³æ®µæ£€æµ‹ç»“æœ
"""

import asyncio
import time
from pathlib import Path

import numpy as np

from cascade.backends import create_vad_backend

# Cascadeæ ¸å¿ƒå¯¼å…¥
from cascade.types import AudioChunk, AudioConfig, AudioFormat, VADConfig


async def quick_vad_demo(audio_file: str = "è¯·é—®ç”µåŠ¨æ±½è½¦å’Œä¼ ç»Ÿæ±½è½¦æ¯”èµ·æ¥å“ªä¸ªæ›´å¥½å•Šï¼Ÿ.wav"):
    """å¿«é€ŸVADå¤„ç†æ¼”ç¤º"""

    print("ğŸš€ Cascadeå¿«é€ŸVADå¤„ç†æ¼”ç¤º")
    print(f"ğŸ“ ç›®æ ‡æ–‡ä»¶: {audio_file}")

    # === 1. é…ç½®è®¾ç½® ===
    print("\nâš™ï¸ é…ç½®Cascadeå‚æ•°...")

    # VADé…ç½®ï¼ˆé’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–ï¼‰
    vad_config = VADConfig(
        backend="silero",                 # ä½¿ç”¨Sileroåç«¯
        threshold=0.3,                    # ä¸­æ–‡è¯­éŸ³è¾ƒä½é˜ˆå€¼
        chunk_duration_ms=512,            # 512mså—ï¼ˆæœ€ä¼˜æ€§èƒ½ï¼‰
        overlap_ms=32,                    # 32msé‡å 
        min_speech_duration_ms=200,       # æœ€å°è¯­éŸ³æ®µ200ms
        workers=4                         # 4ä¸ªå·¥ä½œçº¿ç¨‹
    )

    # éŸ³é¢‘é…ç½®
    audio_config = AudioConfig(
        sample_rate=16000,                # 16kHzæ ‡å‡†é‡‡æ ·ç‡
        channels=1,                       # å•å£°é“
        format=AudioFormat.WAV
    )

    # å¤„ç†å™¨é…ç½® - æš‚æ—¶ä¸ä½¿ç”¨å®Œæ•´å¤„ç†å™¨ï¼Œç›´æ¥ä½¿ç”¨VADåç«¯

    print("âœ… é…ç½®å®Œæˆ")

    # === 2. åŠ è½½çœŸå®éŸ³é¢‘æ•°æ® ===
    print("\nğŸµ å‡†å¤‡éŸ³é¢‘æ•°æ®...")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå…ˆæ£€æŸ¥å½“å‰ç›®å½•ï¼Œå†æ£€æŸ¥ä¸Šçº§ç›®å½•ï¼‰
    audio_path = Path(audio_file)
    if not audio_path.exists():
        # å°è¯•åœ¨ä¸Šçº§ç›®å½•æŸ¥æ‰¾
        parent_path = Path("..") / audio_file
        if parent_path.exists():
            audio_path = parent_path
            print(f"ğŸ“‚ åœ¨ä¸Šçº§ç›®å½•æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {parent_path}")
        else:
            print("ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ¨¡æ‹Ÿè¯­éŸ³æ•°æ®è¿›è¡Œæ¼”ç¤º...")
            audio_data = create_simulation_audio()

    if audio_path.exists():
        print(f"ğŸ“‚ åŠ è½½çœŸå®éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        try:
            import wave
            with wave.open(str(audio_path), 'rb') as wav_file:
                # è·å–éŸ³é¢‘å‚æ•°
                sample_rate = wav_file.getframerate()
                channels = wav_file.getnchannels()
                sample_width = wav_file.getsampwidth()
                n_frames = wav_file.getnframes()

                print(f"  ğŸ“Š éŸ³é¢‘å‚æ•°: {sample_rate}Hz, {channels}å£°é“, {sample_width*8}ä½, {n_frames/sample_rate:.2f}ç§’")

                # è¯»å–éŸ³é¢‘æ•°æ®
                raw_audio = wav_file.readframes(n_frames)

                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                if sample_width == 2:  # 16ä½
                    audio_data = np.frombuffer(raw_audio, dtype=np.int16).astype(np.float32) / 32768.0
                elif sample_width == 4:  # 32ä½
                    audio_data = np.frombuffer(raw_audio, dtype=np.int32).astype(np.float32) / 2147483648.0
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„ä½æ·±: {sample_width*8}ä½")

                # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬ä¸ºå•å£°é“
                if channels == 2:
                    audio_data = audio_data.reshape(-1, 2).mean(axis=1)

                # é‡é‡‡æ ·åˆ°16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
                if sample_rate != 16000:
                    print(f"  ğŸ”„ é‡é‡‡æ ·: {sample_rate}Hz -> 16000Hz")
                    from scipy import signal
                    audio_data = signal.resample(audio_data, int(len(audio_data) * 16000 / sample_rate))

                print(f"âœ… éŸ³é¢‘åŠ è½½æˆåŠŸ: {len(audio_data)/16000:.2f}ç§’, {len(audio_data)}ä¸ªé‡‡æ ·ç‚¹")

        except Exception as e:
            print(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
            print("ğŸ“ ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³æ•°æ®è¿›è¡Œæ¼”ç¤º...")
            audio_data = create_simulation_audio()

    # === 3. åˆå§‹åŒ–VADç³»ç»Ÿ ===
    print("\nğŸ¤– åˆå§‹åŒ–Silero VADç³»ç»Ÿ...")

    start_time = time.time()

    # åˆ›å»ºVADåç«¯
    backend = create_vad_backend(vad_config)
    await backend.initialize()

    init_time = time.time() - start_time
    print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ: {init_time:.3f}ç§’")

    # === 4. é«˜æ€§èƒ½VADå¤„ç† ===
    print("\nâš¡ å¼€å§‹VADå¤„ç†...")

    # å°†éŸ³é¢‘åˆ†å‰²ä¸ºå—
    chunk_size = 8192  # 512ms @ 16kHz
    results = []
    speech_segments = []

    print(f"ğŸ“¦ éŸ³é¢‘åˆ†å—: {len(audio_data)//chunk_size + 1}ä¸ªå— x {chunk_size/16000*1000:.0f}ms")

    # å¼€å§‹å¤„ç†
    processing_start = time.time()

    print("ğŸ” VADæ£€æµ‹ç»“æœ:")
    print("=" * 60)

    for i in range(0, len(audio_data), chunk_size):
        chunk_data = audio_data[i:i+chunk_size]
        if len(chunk_data) < chunk_size:
            # æœ€åä¸€å—è¡¥é›¶
            padded_chunk = np.zeros(chunk_size, dtype=np.float32)
            padded_chunk[:len(chunk_data)] = chunk_data
            chunk_data = padded_chunk

        # åˆ›å»ºéŸ³é¢‘å—
        chunk = AudioChunk(
            data=chunk_data,
            sequence_number=i // chunk_size,
            start_frame=i,
            chunk_size=len(chunk_data),
            timestamp_ms=i / 16000 * 1000,
            sample_rate=16000
        )

        # VADæ¨ç†
        result = backend.process_chunk(chunk)
        results.append(result)

        # å®æ—¶æ˜¾ç¤ºç»“æœ
        time_str = f"{result.start_ms/1000:.2f}-{result.end_ms/1000:.2f}s"
        if result.is_speech:
            status = "ğŸ—£ï¸ è¯­éŸ³"
            speech_segments.append({
                'start': result.start_ms/1000,
                'end': result.end_ms/1000,
                'probability': result.probability
            })
        else:
            status = "ğŸ”‡ é™éŸ³"

        print(f"{status} | {time_str} | æ¦‚ç‡: {result.probability:.3f}")

    processing_time = time.time() - processing_start

    # === 5. ç»“æœåˆ†æ ===
    print("=" * 60)
    print("\nğŸ“Š å¤„ç†ç»“æœåˆ†æ:")

    total_chunks = len(results)
    speech_chunks = sum(1 for r in results if r.is_speech)
    avg_probability = np.mean([r.probability for r in results])

    print("  ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"    - éŸ³é¢‘æ€»æ—¶é•¿: {len(audio_data)/16000:.2f}ç§’")
    print(f"    - å¤„ç†å—æ•°: {total_chunks}")
    print(f"    - è¯­éŸ³å—æ•°: {speech_chunks}")
    print(f"    - é™éŸ³å—æ•°: {total_chunks - speech_chunks}")
    print(f"    - å¹³å‡æ¦‚ç‡: {avg_probability:.3f}")
    print(f"    - å¤„ç†è€—æ—¶: {processing_time:.3f}ç§’")

    if speech_segments:
        print("\n  ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³æ®µ:")
        for i, segment in enumerate(speech_segments, 1):
            duration = segment['end'] - segment['start']
            print(f"    {i}. {segment['start']:.2f}s - {segment['end']:.2f}s "
                  f"(æ—¶é•¿: {duration:.2f}s, æ¦‚ç‡: {segment['probability']:.3f})")

        total_speech_duration = sum(s['end'] - s['start'] for s in speech_segments)
        speech_ratio = total_speech_duration / (len(audio_data)/16000) * 100
        print(f"    è¯­éŸ³æ¯”ä¾‹: {speech_ratio:.1f}%")

    # === 6. æ€§èƒ½æŒ‡æ ‡ ===
    print("\n  âš¡ æ€§èƒ½æŒ‡æ ‡:")
    print(f"    - å¹³å‡å»¶è¿Ÿ: {(processing_time/total_chunks)*1000:.2f}ms/å—")
    print(f"    - å®æ—¶å€ç‡: {(len(audio_data)/16000) / processing_time:.1f}x")
    print(f"    - ååé‡: {total_chunks / processing_time:.1f} chunks/s")

    await backend.close()

    print("\nğŸ‰ VADå¤„ç†å®Œæˆï¼")
    print("\nğŸ’¡ æç¤º:")
    print("  - å°†çœŸå®çš„WAVæ–‡ä»¶æ”¾åœ¨å½“å‰ç›®å½•ï¼Œå³å¯å¤„ç†çœŸå®è¯­éŸ³")
    print("  - è°ƒæ•´vad_config.thresholdå¯ä»¥æ”¹å˜æ£€æµ‹æ•æ„Ÿåº¦")
    print("  - æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼å’Œé‡‡æ ·ç‡")
    print("  - çº¿ç¨‹æ•°å¯æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´ä»¥è·å¾—æœ€ä½³æ€§èƒ½")


# === è¾…åŠ©å‡½æ•° ===

def create_simulation_audio():
    """åˆ›å»ºæ¨¡æ‹Ÿä¸­æ–‡è¯­éŸ³æ•°æ®ç”¨äºæ¼”ç¤º"""
    print("ğŸ™ï¸ ç”Ÿæˆæ¨¡æ‹Ÿä¸­æ–‡è¯­éŸ³ä¿¡å·...")

    # åˆ›å»º10ç§’æ¨¡æ‹ŸéŸ³é¢‘ï¼šåŒ…å«3æ®µè¯­éŸ³å’Œ2æ®µé™éŸ³
    duration = 10.0  # 10ç§’
    sample_rate = 16000
    total_samples = int(duration * sample_rate)

    # ç”Ÿæˆæ¨¡æ‹Ÿçš„ä¸­æ–‡è¯­éŸ³ä¿¡å·
    t = np.linspace(0, duration, total_samples)
    audio_data = np.zeros(total_samples, dtype=np.float32)

    # è¯­éŸ³æ®µ1: 0.2-2.5ç§’ "è¯·é—®ç”µåŠ¨æ±½è½¦"
    mask1 = (t >= 0.2) & (t <= 2.5)
    audio_data[mask1] = (
        0.4 * np.sin(2 * np.pi * 180 * t[mask1]) +  # åŸºé¢‘
        0.3 * np.sin(2 * np.pi * 360 * t[mask1]) +  # äºŒæ¬¡è°æ³¢
        0.2 * np.sin(2 * np.pi * 540 * t[mask1]) +  # ä¸‰æ¬¡è°æ³¢
        0.1 * np.random.randn(np.sum(mask1))        # å™ªå£°
    )

    # é™éŸ³æ®µ: 2.5-3.5ç§’

    # è¯­éŸ³æ®µ2: 3.5-6ç§’ "å’Œä¼ ç»Ÿæ±½è½¦æ¯”èµ·æ¥"
    mask2 = (t >= 3.5) & (t <= 6.0)
    audio_data[mask2] = (
        0.3 * np.sin(2 * np.pi * 200 * t[mask2]) +
        0.3 * np.sin(2 * np.pi * 400 * t[mask2]) +
        0.2 * np.sin(2 * np.pi * 600 * t[mask2]) +
        0.1 * np.random.randn(np.sum(mask2))
    )

    # é™éŸ³æ®µ: 6-6.8ç§’

    # è¯­éŸ³æ®µ3: 6.8-9ç§’ "å“ªä¸ªæ›´å¥½å•Šï¼Ÿ"
    mask3 = (t >= 6.8) & (t <= 9.0)
    audio_data[mask3] = (
        0.35 * np.sin(2 * np.pi * 220 * t[mask3]) +
        0.25 * np.sin(2 * np.pi * 440 * t[mask3]) +
        0.15 * np.sin(2 * np.pi * 660 * t[mask3]) +
        0.1 * np.random.randn(np.sum(mask3))
    )

    # æ·»åŠ èƒŒæ™¯å™ªå£°
    background_noise = 0.02 * np.random.randn(total_samples)
    audio_data += background_noise

    # å½’ä¸€åŒ–
    audio_data = audio_data / np.max(np.abs(audio_data)) * 0.8

    print(f"âœ… æ¨¡æ‹ŸéŸ³é¢‘ç”Ÿæˆå®Œæˆ: {duration}ç§’, 3ä¸ªè¯­éŸ³æ®µ")
    return audio_data.astype(np.float32)


def create_test_audio_file(filename: str = "è¯·é—®ç”µåŠ¨æ±½è½¦å’Œä¼ ç»Ÿæ±½è½¦æ¯”èµ·æ¥å“ªä¸ªæ›´å¥½å•Šï¼Ÿ.wav"):
    """åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰"""
    import wave

    print(f"ğŸµ åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {filename}")

    # ç”Ÿæˆ10ç§’æµ‹è¯•éŸ³é¢‘
    sample_rate = 16000
    duration = 10.0
    t = np.linspace(0, duration, int(sample_rate * duration))

    # åˆ›å»ºåŒ…å«å¤šä¸ªè¯­éŸ³æ®µçš„æµ‹è¯•ä¿¡å·
    signal = np.zeros_like(t)

    # è¯­éŸ³æ®µ1: 0.5-3ç§’
    mask1 = (t >= 0.5) & (t <= 3.0)
    signal[mask1] = 0.3 * (np.sin(2*np.pi*200*t[mask1]) + 0.5*np.sin(2*np.pi*400*t[mask1]))

    # è¯­éŸ³æ®µ2: 4-7ç§’
    mask2 = (t >= 4.0) & (t <= 7.0)
    signal[mask2] = 0.4 * (np.sin(2*np.pi*250*t[mask2]) + 0.3*np.sin(2*np.pi*500*t[mask2]))

    # è¯­éŸ³æ®µ3: 8-9.5ç§’
    mask3 = (t >= 8.0) & (t <= 9.5)
    signal[mask3] = 0.35 * (np.sin(2*np.pi*180*t[mask3]) + 0.4*np.sin(2*np.pi*360*t[mask3]))

    # æ·»åŠ å™ªå£°
    signal += 0.02 * np.random.randn(len(signal))

    # å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸º16ä½æ•´æ•°
    signal = signal / np.max(np.abs(signal)) * 0.8
    signal_int16 = (signal * 32767).astype(np.int16)

    # ä¿å­˜ä¸ºWAVæ–‡ä»¶
    with wave.open(filename, 'wb') as wav_file:
        wav_file.setnchannels(1)      # å•å£°é“
        wav_file.setsampwidth(2)      # 16ä½
        wav_file.setframerate(sample_rate)
        wav_file.writeframes(signal_int16.tobytes())

    print(f"âœ… æµ‹è¯•éŸ³é¢‘æ–‡ä»¶å·²åˆ›å»º: {filename}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ Cascadeé«˜æ€§èƒ½å¹¶è¡ŒVADå¤„ç†å¿«é€Ÿæ¼”ç¤º")
    print("=" * 50)

    # å¯é€‰ï¼šåˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    # create_test_audio_file()

    # è¿è¡Œå¿«é€Ÿæ¼”ç¤º
    await quick_vad_demo("è¯·é—®ç”µåŠ¨æ±½è½¦å’Œä¼ ç»Ÿæ±½è½¦æ¯”èµ·æ¥å“ªä¸ªæ›´å¥½å•Šï¼Ÿ.wav")


if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main())

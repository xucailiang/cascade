#!/usr/bin/env python3
"""
æµ‹è¯•Silero VADæµå¼æ¨ç†
ä¸“æ³¨äºæ¼”ç¤ºVADIteratorçš„è¯­éŸ³æ®µæ£€æµ‹åŠŸèƒ½
"""

import asyncio
import wave
from pathlib import Path

import numpy as np

from cascade.backends import create_vad_backend
from cascade.types import AudioChunk, VADConfig


async def test_silero_streaming_vad():
    """æµ‹è¯•Silero VADæµå¼è¯­éŸ³æ®µæ£€æµ‹"""
    print("="*80)
    print("ğŸš€ Silero VADæµå¼è¯­éŸ³æ®µæ£€æµ‹æµ‹è¯•")
    print("="*80)

    # åŠ è½½æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    audio_file = Path("è¯·é—®ç”µåŠ¨æ±½è½¦å’Œä¼ ç»Ÿæ±½è½¦æ¯”èµ·æ¥å“ªä¸ªæ›´å¥½å•Šï¼Ÿ.wav")

    if not audio_file.exists():
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return

    # è¯»å–éŸ³é¢‘æ–‡ä»¶
    with wave.open(str(audio_file), 'rb') as wav_file:
        frames = wav_file.readframes(wav_file.getnframes())
        sample_rate = wav_file.getframerate()

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        audio_data = np.frombuffer(frames, dtype=np.int16).astype(np.float32)
        # å½’ä¸€åŒ–åˆ°[-1, 1]
        audio_data = audio_data / 32768.0

    print("ğŸ“ éŸ³é¢‘æ–‡ä»¶åŠ è½½æˆåŠŸ:")
    print(f"   æ€»æ ·æœ¬æ•°: {len(audio_data)}")
    print(f"   é‡‡æ ·ç‡: {sample_rate}Hz")
    print(f"   æ€»æ—¶é•¿: {len(audio_data) / sample_rate:.2f}ç§’")
    print()

    # åˆ›å»ºVADé…ç½®ï¼ˆå¯ç”¨æµå¼æ¨¡å¼ï¼‰
    vad_config = VADConfig(
        backend="silero",
        threshold=0.5
    )

    # åˆ›å»ºVADåç«¯
    try:
        backend = create_vad_backend(vad_config)

        # å¯ç”¨æµå¼å¤„ç†æ¨¡å¼
        backend._silero_config.streaming_mode = True
        backend._silero_config.return_seconds = False  # è¿”å›æ ·æœ¬æ•°è€Œéç§’æ•°
        backend._silero_config.onnx = True

        print("âœ… VADåç«¯åˆ›å»ºæˆåŠŸ")

        # åˆå§‹åŒ–åç«¯
        await backend.initialize()
        print("âœ… VADåç«¯åˆå§‹åŒ–æˆåŠŸ")
        print()

        # åˆ›å»ºå®Œæ•´éŸ³é¢‘çš„å¤„ç†å—
        chunk_size = 512  # 16kHzçš„å—å¤§å°
        total_chunks = (len(audio_data) + chunk_size - 1) // chunk_size

        print("ğŸ¤ å¼€å§‹æµå¼VADè¯­éŸ³æ®µæ£€æµ‹:")
        print(f"   å¤„ç†å—æ•°: {total_chunks}")
        print(f"   æ¯å—æ ·æœ¬æ•°: {chunk_size}")
        print(f"   æ¯å—æ—¶é•¿: {chunk_size / sample_rate * 1000:.1f}ms")
        print()

        speech_segments = []  # è®°å½•æ£€æµ‹åˆ°çš„è¯­éŸ³æ®µ
        current_segment = None

        for i in range(total_chunks):
            start_idx = i * chunk_size
            end_idx = min(start_idx + chunk_size, len(audio_data))

            chunk_data = audio_data[start_idx:end_idx]

            # å¦‚æœæœ€åä¸€å—ä¸å¤Ÿå¤§å°ï¼Œå¡«å……é›¶
            if len(chunk_data) < chunk_size:
                padded_data = np.zeros(chunk_size, dtype=np.float32)
                padded_data[:len(chunk_data)] = chunk_data
                chunk_data = padded_data

            chunk = AudioChunk(
                data=chunk_data,
                sequence_number=i,
                start_frame=start_idx,
                chunk_size=chunk_size,
                timestamp_ms=i * (chunk_size * 1000.0 / sample_rate),
                sample_rate=sample_rate
            )

            # å¤„ç†éŸ³é¢‘å—
            result = backend.process_chunk(chunk)

            # è§£æVADIteratorçš„åŸå§‹ç»“æœ
            metadata = result.metadata or {}
            streaming_mode = metadata.get('streaming_mode', False)

            # ä»åç«¯è·å–æœ€åçš„VADIteratorç»“æœ
            if hasattr(backend, '_thread_local') and hasattr(backend._thread_local, 'last_vad_result'):
                vad_result = backend._thread_local.last_vad_result
                if vad_result:
                    if 'start' in vad_result:
                        start_sample = vad_result['start']
                        start_time = start_sample / sample_rate
                        print(f"ğŸ™ï¸  æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹: æ ·æœ¬{start_sample} -> {start_time:.3f}ç§’")
                        current_segment = {'start': start_sample, 'start_time': start_time}

                    elif 'end' in vad_result:
                        end_sample = vad_result['end']
                        end_time = end_sample / sample_rate
                        print(f"ğŸ”‡ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ: æ ·æœ¬{end_sample} -> {end_time:.3f}ç§’")

                        if current_segment:
                            current_segment['end'] = end_sample
                            current_segment['end_time'] = end_time
                            current_segment['duration'] = end_time - current_segment['start_time']
                            speech_segments.append(current_segment)
                            current_segment = None

        print()
        print("ğŸ“Š è¯­éŸ³æ®µæ£€æµ‹ç»“æœ:")
        if speech_segments:
            for i, segment in enumerate(speech_segments, 1):
                print(f"   è¯­éŸ³æ®µ {i}: {segment['start_time']:.3f}s - {segment['end_time']:.3f}s")
                print(f"            æ—¶é•¿: {segment['duration']:.3f}s")
                print(f"            æ ·æœ¬èŒƒå›´: {segment['start']} - {segment['end']}")
        else:
            print("   æœªæ£€æµ‹åˆ°å®Œæ•´çš„è¯­éŸ³æ®µ")

        # å…³é—­åç«¯
        await backend.close()
        print()
        print("âœ… VADåç«¯å·²å…³é—­")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    print()
    print("="*80)
    print("ğŸ‰ Silero VADæµå¼è¯­éŸ³æ®µæ£€æµ‹æµ‹è¯•å®Œæˆ")
    print("="*80)

if __name__ == "__main__":
    asyncio.run(test_silero_streaming_vad())

# Cascade VAD Web演示界面 - 实现指南

本文档提供了Cascade VAD Web演示界面的实现步骤和指南，包括后端FastAPI服务器和前端界面的实现。

## 1. 项目结构

```
web_demo/
├── backend/                # 后端FastAPI服务器
│   ├── app.py             # 主应用入口
│   ├── models.py          # 数据模型
│   ├── routes/            # 路由处理
│   │   ├── __init__.py
│   │   ├── websocket.py   # WebSocket处理
│   │   └── upload.py      # 文件上传处理
│   ├── services/          # 业务逻辑
│   │   ├── __init__.py
│   │   ├── vad_service.py # VAD处理服务
│   │   └── file_service.py # 文件处理服务
│   └── utils/             # 工具函数
│       ├── __init__.py
│       └── performance.py # 性能监控
├── frontend/              # 前端界面
│   ├── package.json       # 前端依赖
│   ├── index.html         # 主页面
│   ├── css/               # 样式文件
│   │   ├── main.css       # 主样式
│   │   └── components.css # 组件样式
│   └── js/                # JavaScript文件
│       ├── main.js        # 主逻辑
│       ├── audio.js       # 音频处理
│       ├── websocket.js   # WebSocket通信
│       └── charts.js      # 图表可视化
└── uploads/               # 文件上传目录
```

## 2. 环境设置

### 2.1 后端环境（使用Poetry）

Cascade项目已经使用Poetry管理依赖，我们需要添加Web演示所需的额外依赖：

```bash
# 在项目根目录执行
poetry add fastapi uvicorn websockets python-multipart
```

### 2.2 前端环境（使用pnpm）

```bash
# 在web_demo/frontend目录执行
mkdir -p web_demo/frontend
cd web_demo/frontend

# 初始化pnpm项目
pnpm init

# 安装依赖
pnpm add chart.js file-saver
```

## 3. 后端实现步骤

### 3.1 创建基础目录结构

```bash
mkdir -p web_demo/backend/routes web_demo/backend/services web_demo/backend/utils web_demo/uploads
```

### 3.2 实现数据模型 (models.py)

创建`web_demo/backend/models.py`文件，实现数据模型：

```python
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field

class VADConfig(BaseModel):
    """VAD配置模型"""
    threshold: float = Field(0.5, ge=0.1, le=0.9, description="语音检测阈值")
    chunk_duration_ms: int = Field(512, description="音频块大小(毫秒)")
    overlap_ms: int = Field(32, description="重叠大小(毫秒)")
    workers: int = Field(4, ge=1, le=8, description="工作线程数")
    backend: str = Field("silero", description="VAD后端")
    
    class Config:
        json_schema_extra = {
            "example": {
                "threshold": 0.5,
                "chunk_duration_ms": 512,
                "overlap_ms": 32,
                "workers": 4,
                "backend": "silero"
            }
        }

class AudioChunk(BaseModel):
    """音频数据块模型"""
    data: List[float] = Field(..., description="音频数据")
    timestamp: int = Field(..., description="客户端时间戳(ms)")
    sequence: int = Field(..., description="序列号")
    sample_rate: int = Field(16000, description="采样率")

class VADResult(BaseModel):
    """VAD检测结果模型"""
    is_speech: bool = Field(..., description="是否为语音")
    probability: float = Field(..., description="置信度")
    start_ms: float = Field(..., description="开始时间(ms)")
    end_ms: Optional[float] = Field(None, description="结束时间(ms)")
    chunk_id: int = Field(..., description="对应的音频块ID")
    processing_time_ms: float = Field(..., description="处理耗时")

class PerformanceMetrics(BaseModel):
    """性能指标模型"""
    avg_latency_ms: float = Field(..., description="平均延迟")
    max_latency_ms: float = Field(..., description="最大延迟")
    throughput_chunks_per_sec: float = Field(..., description="吞吐量")
    active_threads: int = Field(..., description="活跃线程数")
    buffer_utilization: float = Field(..., description="缓冲区利用率")
    cpu_usage: float = Field(..., description="CPU使用率")
    memory_usage_mb: float = Field(..., description="内存使用")
    timestamp: int = Field(..., description="时间戳")

class WebSocketMessage(BaseModel):
    """WebSocket消息基类"""
    type: str = Field(..., description="消息类型")

class AudioChunkMessage(WebSocketMessage):
    """音频数据块消息"""
    type: str = "audio_chunk"
    data: List[float] = Field(..., description="音频数据")
    timestamp: int = Field(..., description="客户端时间戳(ms)")
    sequence: int = Field(..., description="序列号")
    sample_rate: int = Field(16000, description="采样率")

class ConfigUpdateMessage(WebSocketMessage):
    """配置更新消息"""
    type: str = "config_update"
    config: Dict[str, Any] = Field(..., description="配置参数")

class StartRecordingMessage(WebSocketMessage):
    """开始录音消息"""
    type: str = "start_recording"
    config: Optional[Dict[str, Any]] = Field(None, description="配置参数")

class StopRecordingMessage(WebSocketMessage):
    """停止录音消息"""
    type: str = "stop_recording"

class VADResultMessage(WebSocketMessage):
    """VAD结果消息"""
    type: str = "vad_result"
    is_speech: bool = Field(..., description="是否为语音")
    probability: float = Field(..., description="置信度")
    start_ms: float = Field(..., description="开始时间(ms)")
    end_ms: Optional[float] = Field(None, description="结束时间(ms)")
    chunk_id: int = Field(..., description="对应的音频块ID")
    processing_time_ms: float = Field(..., description="处理耗时")

class PerformanceMetricsMessage(WebSocketMessage):
    """性能指标消息"""
    type: str = "performance_metrics"
    metrics: Dict[str, Any] = Field(..., description="性能指标")
    timestamp: int = Field(..., description="时间戳")

class StatusMessage(WebSocketMessage):
    """状态消息"""
    type: str = "status"
    status: str = Field(..., description="状态")
    message: str = Field(..., description="消息")
    timestamp: int = Field(..., description="时间戳")

class ErrorMessage(WebSocketMessage):
    """错误消息"""
    type: str = "error"
    code: str = Field(..., description="错误代码")
    message: str = Field(..., description="错误消息")
    details: Optional[Dict[str, Any]] = Field(None, description="错误详情")

class FileUploadResponse(BaseModel):
    """文件上传响应"""
    status: str = Field(..., description="状态")
    file_id: str = Field(..., description="文件ID")
    filename: str = Field(..., description="文件名")
    duration_sec: float = Field(..., description="时长(秒)")
    sample_rate: int = Field(..., description="采样率")
    channels: int = Field(..., description="声道数")
    format: str = Field(..., description="格式")
    results: Optional[List[Dict[str, Any]]] = Field(None, description="VAD结果")
    performance: Optional[Dict[str, Any]] = Field(None, description="性能指标")
```

### 3.3 实现VAD服务 (services/vad_service.py)

创建`web_demo/backend/services/vad_service.py`文件，实现VAD处理服务：

```python
import asyncio
import time
import numpy as np
import logging
from typing import List, Dict, Any, Optional, AsyncIterator
import os
import sys

# 添加项目根目录到Python路径
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../')))

# 导入Cascade模块
from cascade.types import VADConfig as CascadeVADConfig, AudioConfig, AudioChunk as CascadeAudioChunk
from cascade.processor import VADProcessor, VADProcessorConfig
from cascade.backends import create_vad_backend

from ..models import VADResult, PerformanceMetrics

logger = logging.getLogger(__name__)

class VADService:
    """VAD处理服务"""
    
    def __init__(self):
        self.processor = None
        self.config = None
        self.is_initialized = False
        self.active_connections = set()
    
    async def initialize(self, config: Dict[str, Any]) -> bool:
        """初始化VAD处理器"""
        try:
            # 创建Cascade配置
            vad_config = CascadeVADConfig(
                threshold=config.get('threshold', 0.5),
                chunk_duration_ms=config.get('chunk_duration_ms', 512),
                overlap_ms=config.get('overlap_ms', 32),
                backend=config.get('backend', 'silero')
            )
            
            audio_config = AudioConfig(
                sample_rate=config.get('sample_rate', 16000),
                channels=config.get('channels', 1)
            )
            
            processor_config = VADProcessorConfig(
                vad_config=vad_config,
                audio_config=audio_config,
                thread_pool_config=None,  # 使用默认配置
                buffer_capacity_seconds=3.0,
                max_queue_size=64,
                enable_performance_monitoring=True
            )
            
            # 创建VAD后端
            backend = create_vad_backend(vad_config)
            await backend.initialize()
            
            # 创建VAD处理器
            self.processor = VADProcessor(processor_config)
            await self.processor.initialize(backend)
            
            self.config = config
            self.is_initialized = True
            
            logger.info("VAD处理器初始化成功")
            return True
            
        except Exception as e:
            logger.error(f"VAD处理器初始化失败: {e}")
            return False
    
    async def process_audio_chunk(self, audio_data: List[float], sample_rate: int, chunk_id: int) -> VADResult:
        """处理单个音频块"""
        if not self.is_initialized or not self.processor:
            raise RuntimeError("VAD处理器未初始化")
        
        start_time = time.time()
        
        # 创建Cascade音频块
        audio_chunk = CascadeAudioChunk(
            data=np.array(audio_data, dtype=np.float32),
            sequence_number=chunk_id,
            start_frame=0,
            chunk_size=len(audio_data),
            timestamp_ms=0,
            sample_rate=sample_rate
        )
        
        # 处理音频块
        cascade_result = await self.processor.process_chunk(audio_chunk)
        
        processing_time_ms = (time.time() - start_time) * 1000
        
        # 转换为API模型
        result = VADResult(
            is_speech=cascade_result.is_speech,
            probability=cascade_result.probability,
            start_ms=cascade_result.start_ms,
            end_ms=cascade_result.end_ms,
            chunk_id=chunk_id,
            processing_time_ms=processing_time_ms
        )
        
        return result
    
    async def process_audio_stream(self, audio_chunks: AsyncIterator[np.ndarray]) -> AsyncIterator[VADResult]:
        """处理音频流"""
        if not self.is_initialized or not self.processor:
            raise RuntimeError("VAD处理器未初始化")
        
        async for result in self.processor.process_stream(audio_chunks):
            yield VADResult(
                is_speech=result.is_speech,
                probability=result.probability,
                start_ms=result.start_ms,
                end_ms=result.end_ms,
                chunk_id=result.chunk_id,
                processing_time_ms=0  # 流式处理中无法获取单个块的处理时间
            )
    
    async def process_file(self, file_path: str, config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """处理音频文件"""
        if config:
            await self.update_config(config)
        
        # 读取音频文件
        import wave
        with wave.open(file_path, 'rb') as wav_file:
            # 获取音频参数
            sample_rate = wav_file.getframerate()
            channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            n_frames = wav_file.getnframes()
            
            # 读取音频数据
            raw_audio = wav_file.readframes(n_frames)
            
            # 转换为numpy数组
            if sample_width == 2:  # 16位
                audio_data = np.frombuffer(raw_audio, dtype=np.int16).astype(np.float32) / 32768.0
            elif sample_width == 4:  # 32位
                audio_data = np.frombuffer(raw_audio, dtype=np.int32).astype(np.float32) / 2147483648.0
            else:
                raise ValueError(f"不支持的位深: {sample_width*8}位")
            
            # 如果是立体声，转为单声道
            if channels == 2:
                audio_data = audio_data.reshape(-1, 2).mean(axis=1)
            
            # 重采样到16kHz（如果需要）
            if sample_rate != 16000:
                from scipy import signal
                audio_data = signal.resample(audio_data, int(len(audio_data) * 16000 / sample_rate))
                sample_rate = 16000
        
        # 处理音频数据
        start_time = time.time()
        
        # 将音频分割为块
        chunk_size = int(sample_rate * self.config.get('chunk_duration_ms', 512) / 1000)
        results = []
        
        for i in range(0, len(audio_data), chunk_size):
            chunk_data = audio_data[i:i+chunk_size]
            if len(chunk_data) < chunk_size:
                # 最后一块补零
                padded_chunk = np.zeros(chunk_size, dtype=np.float32)
                padded_chunk[:len(chunk_data)] = chunk_data
                chunk_data = padded_chunk
            
            # 创建音频块
            audio_chunk = CascadeAudioChunk(
                data=chunk_data,
                sequence_number=i // chunk_size,
                start_frame=i,
                chunk_size=len(chunk_data),
                timestamp_ms=i / sample_rate * 1000,
                sample_rate=sample_rate
            )
            
            # 处理音频块
            result = await self.processor.process_chunk(audio_chunk)
            
            if result.is_speech:
                results.append({
                    'is_speech': result.is_speech,
                    'probability': result.probability,
                    'start_ms': result.start_ms,
                    'end_ms': result.end_ms
                })
        
        processing_time = time.time() - start_time
        
        # 获取性能指标
        metrics = self.processor.get_performance_metrics()
        
        return {
            'duration_sec': len(audio_data) / sample_rate,
            'sample_rate': sample_rate,
            'channels': 1,  # 处理后都是单声道
            'format': 'wav',
            'results': results,
            'performance': {
                'total_processing_time_ms': processing_time * 1000,
                'realtime_factor': (len(audio_data) / sample_rate) / processing_time,
                'avg_latency_ms': metrics.avg_latency_ms if hasattr(metrics, 'avg_latency_ms') else 0
            }
        }
    
    async def update_config(self, config: Dict[str, Any]) -> bool:
        """更新VAD配置"""
        try:
            # 如果处理器已初始化，需要关闭并重新初始化
            if self.is_initialized and self.processor:
                await self.processor.close()
                self.is_initialized = False
            
            # 使用新配置初始化
            success = await self.initialize(config)
            return success
            
        except Exception as e:
            logger.error(f"更新VAD配置失败: {e}")
            return False
    
    async def get_performance_metrics(self) -> PerformanceMetrics:
        """获取性能指标"""
        if not self.is_initialized or not self.processor:
            raise RuntimeError("VAD处理器未初始化")
        
        # 获取Cascade性能指标
        cascade_metrics = self.processor.get_performance_metrics()
        
        # 获取系统资源使用情况
        import psutil
        process = psutil.Process(os.getpid())
        
        # 转换为API模型
        metrics = PerformanceMetrics(
            avg_latency_ms=cascade_metrics.avg_latency_ms if hasattr(cascade_metrics, 'avg_latency_ms') else 0,
            max_latency_ms=cascade_metrics.max_latency_ms if hasattr(cascade_metrics, 'max_latency_ms') else 0,
            throughput_chunks_per_sec=cascade_metrics.throughput_qps if hasattr(cascade_metrics, 'throughput_qps') else 0,
            active_threads=cascade_metrics.active_threads if hasattr(cascade_metrics, 'active_threads') else 0,
            buffer_utilization=cascade_metrics.buffer_utilization if hasattr(cascade_metrics, 'buffer_utilization') else 0,
            cpu_usage=process.cpu_percent() / 100.0,
            memory_usage_mb=process.memory_info().rss / (1024 * 1024),
            timestamp=int(time.time() * 1000)
        )
        
        return metrics
    
    async def close(self):
        """关闭VAD处理器"""
        if self.is_initialized and self.processor:
            await self.processor.close()
            self.is_initialized = False
            logger.info("VAD处理器已关闭")

# 创建全局VAD服务实例
vad_service = VADService()
```

### 3.4 实现文件服务 (services/file_service.py)

创建`web_demo/backend/services/file_service.py`文件，实现文件处理服务：

```python
import os
import uuid
import logging
import aiofiles
from typing import Dict, Any, Optional
import mimetypes

from .vad_service import vad_service

logger = logging.getLogger(__name__)

# 上传目录
UPLOAD_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../uploads'))

# 确保上传目录存在
os.makedirs(UPLOAD_DIR, exist_ok=True)

class FileService:
    """文件处理服务"""
    
    @staticmethod
    async def save_uploaded_file(file_content: bytes, filename: str) -> str:
        """保存上传的文件"""
        # 生成唯一文件ID
        file_id = str(uuid.uuid4())
        
        # 获取文件扩展名
        _, ext = os.path.splitext(filename)
        
        # 保存文件
        file_path = os.path.join(UPLOAD_DIR, f"{file_id}{ext}")
        
        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(file_content)
        
        logger.info(f"文件已保存: {file_path}")
        
        return file_path
    
    @staticmethod
    async def process_audio_file(file_path: str, config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """处理音频文件"""
        try:
            # 获取文件名
            filename = os.path.basename(file_path)
            
            # 处理音频文件
            result = await vad_service.process_file(file_path, config)
            
            # 添加文件信息
            result['file_id'] = os.path.splitext(filename)[0]
            result['filename'] = filename
            result['status'] = 'success'
            
            return result
            
        except Exception as e:
            logger.error(f"处理音频文件失败: {e}")
            return {
                'status': 'error',
                'file_id': os.path.splitext(os.path.basename(file_path))[0],
                'filename': os.path.basename(file_path),
                'error': str(e)
            }
    
    @staticmethod
    def validate_audio_file(content_type: str, file_size: int) -> Dict[str, Any]:
        """验证音频文件"""
        # 检查文件类型
        valid_types = ['audio/wav', 'audio/x-wav', 'audio/mpeg', 'audio/mp3', 'audio/flac', 'audio/ogg']
        if content_type not in valid_types:
            return {
                'valid': False,
                'error': 'unsupported_format',
                'message': f"不支持的文件格式: {content_type}",
                'details': {
                    'format': content_type,
                    'supported_formats': valid_types
                }
            }
        
        # 检查文件大小
        max_size = 50 * 1024 * 1024  # 50MB
        if file_size > max_size:
            return {
                'valid': False,
                'error': 'file_too_large',
                'message': f"文件过大: {file_size} 字节 (最大 {max_size} 字节)",
                'details': {
                    'size': file_size,
                    'max_size': max_size
                }
            }
        
        return {'valid': True}

# 创建全局文件服务实例
file_service = FileService()
```

### 3.5 实现WebSocket路由 (routes/websocket.py)

创建`web_demo/backend/routes/websocket.py`文件，实现WebSocket处理：

```python
import json
import logging
import asyncio
import time
import numpy as np
from typing import Dict, Any, List, Optional
from fastapi import WebSocket, WebSocketDisconnect, APIRouter
import traceback

from ..services.vad_service import vad_service
from ..models import (
    WebSocketMessage, AudioChunkMessage, ConfigUpdateMessage,
    StartRecordingMessage, StopRecordingMessage, VADResultMessage,
    PerformanceMetricsMessage, StatusMessage, ErrorMessage
)

logger = logging.getLogger(__name__)

router = APIRouter()

# 活跃的WebSocket连接
active_connections: List[WebSocket] = []

# 性能监控任务
performance_monitor_task = None

async def performance_monitor():
    """性能监控任务"""
    while active_connections:
        try:
            # 获取性能指标
            metrics = await vad_service.get_performance_metrics()
            
            # 广播给所有连接
            for connection in active_connections:
                await connection.send_json({
                    'type': 'performance_metrics',
                    'metrics': metrics.dict(),
                    'timestamp': int(time.time() * 1000)
                })
            
            # 每秒更新一次
            await asyncio.sleep(1)
            
        except Exception as e:
            logger.error(f"性能监控错误: {e}")
            await asyncio.sleep(1)

@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket端点"""
    # 接受连接
    await websocket.accept()
    
    # 添加到活跃连接
    active_connections.append(websocket)
    
    # 启动性能监控任务
    global performance_monitor_task
    if performance_monitor_task is None or performance_monitor_task.done():
        performance_monitor_task = asyncio.create_task(performance_monitor())
    
    # 发送状态消息
    await websocket.send_json({
        'type': 'status',
        'status': 'connected',
        'message': '连接成功',
        'timestamp': int(time.time() * 1000)
    })
    
    try:
        # 初始化VAD处理器（如果尚未初始化）
        if not vad_service.is_initialized:
            # 使用默认配置初始化
            default_config = {
                'threshold': 0.5,
                'chunk_duration_ms': 512,
                'overlap_ms': 32,
                'backend': 'silero',
                'sample_rate': 16000,
                'channels': 1
            }
            
            success = await vad_service.initialize(default_config)
            
            if not success:
                await websocket.send_json({
                    'type': 'error',
                    'code': 'initialization_failed',
                    'message': 'VAD处理器初始化失败'
                })
                return
        
        # 处理消息
        while True:
            # 接收消息
            data = await websocket.receive_text()
            
            try:
                # 解析JSON消息
                message_data = json.loads(data)
                message_type = message_data.get('type')
                
                # 处理不同类型的消息
                if message_type == 'audio_chunk':
                    # 解析音频数据块消息
                    message = AudioChunkMessage(**message_data)
                    
                    # 处理音频数据
                    result = await vad_service.process_audio_chunk(
                        message.data,
                        message.sample_rate,
                        message.sequence
                    )
                    
                    # 发送结果
                    await websocket.send_json({
                        'type': 'vad_result',
                        'is_speech': result.is_speech,
                        'probability': result.probability,
                        'start_ms': result.start_ms,
                        'end_ms': result.end_ms,
                        'chunk_id': result.chunk_id,
                        'processing_time_ms': result.processing_time_ms
                    })
                    
                elif message_type == 'config_update':
                    # 解析配置更新消息
                    message = ConfigUpdateMessage(**message_data)
                    
                    # 更新配置
                    success = await vad_service.update_config(message.config)
                    
                    # 发送状态
                    if success:
                        await websocket.send_json({
                            'type': 'status',
                            'status': 'config_updated',
                            'message': '配置已更新',
                            'timestamp': int(time.time() * 1000)
                        })
                    else:
                        await websocket.send_json({
                            'type': 'error',
                            'code': 'config_update_failed',
                            'message': '配置更新失败'
                        })
                    
                elif message_type == 'start_recording':
                    # 解析开始录音消息
                    message = StartRecordingMessage(**message_data)
                    
                    # 如果提供了配置，更新配置
                    if message.config:
                        await vad_service.update_config(message.config)
                    
                    # 发送状态
                    await websocket.send_json({
                        'type': 'status',
                        'status': 'recording_started',
                        'message': '录音已开始',
                        'timestamp': int(time.time() * 1000)
                    })
                    
                elif message_type == 'stop_recording':
                    # 解析停止录音消息
                    message = StopRecordingMessage(**message_data)
                    
                    # 发送状态
                    await websocket.send_json({
                        'type': 'status',
                        'status': 'recording_stopped',
                        'message': '录音已停止',
                        'timestamp': int(time.time() * 1000)
                    })
                    
                elif message_type == 'ping':
                    # 心